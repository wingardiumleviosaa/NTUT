

## 摘要
本論文提出了一種新穎的演算法，從二維攝影機畫面中提取四元數，以估算人類骨架姿勢。姿勢估算問題通常通過使用立體攝影機和慣性測量單元來獲取深度和三維空間中點的歐幾里得距離進行測量。然而，這些設備的使用伴隨著較高的信號處理延遲和顯著的財務成本。本演算法利用MediaPipe，一個用於構建人類姿勢估算感知管道的框架，從二維畫面中提取四元數，該畫面捕捉到人類物體影像，且延遲低於50毫秒，同時也能在僅有單攝影機畫面和低計算資源的邊緣設備上部署，特別適用於涉及自動機器人和類似模型的智慧交通系統中最後一刻檢測和反應的使用案例。此演算法旨在突破資金限制，提升機器人研究人員設計控制系統的可及性。  
關鍵詞—四元數、二維攝影機、姿勢估算、MediaPipe、低功耗、低延遲、嵌入式電腦視覺。

## I. 引言  
基本的場景分析任務如行人檢測和定位，通常需要生成四元數來估算目標物體的方位。有時，這些技術會使用立體攝影機和慣性測量單元來匹配特徵點[1]，或是使用涉及昂貴硬體元件的方法，這些方法通常伴隨較大的延遲和計算資源消耗。

直觀來說，為了泛化潛在的使用案例，將計算靠近系統並消除算法中涉及的昂貴硬體，將是解決成本和延遲問題的進一步方向。為了達到這一目標，必須注意現有姿勢估算模型所接受的硬體依賴輸入。就此人類姿勢估算的特定使用案例而言，目標姿勢物體內部點的深度並且同時處理兩條影像串流的能力至少達到了最低要求。為了解決這些問題，我們選擇了一個僅使用單一二維攝影機且硬體設備中包含拍攝到人體畫面的系統，以降低成本。此外，在軟體端實施了一個基於深度學習的專門解決方案，來彌補深度感知的損失，並在資源較低的邊緣設備上保持低延遲。目標是模擬現代慣性測量單元（IMU）為人體骨架姿勢中相鄰關節之間的任意邊提供的四元數輸出[2]。

![[Figure1.png]]
圖 1. 演示了用於根據生成的四元數計算行人物體的方向角的用例的新穎演算法。

## II. 相關研究  
在他們開發基於四元數的遞迴模型以預測人體運動的研究中，Pavllo 等人指出，人體運動是一個具有高度內在不確定性的隨機序列過程[3]。雖然深度學習方法在預測人體骨架姿勢方面取得了成功，但它們通常計算成本高昂，尤其是在移動機器人和自動駕駛車輛導航中，成本因素常被妥協，主邊緣處理單元上增加更多核心來進行計算[4]。近來，基於 Nvidia GPU 的邊緣計算單元的零售成本下降，使這種折衷方案變得更具可行性，但最好是通過改進 CPU 基礎的系統來更有效地處理所需計算[5]。Eberly 指出，四元數和旋轉矩陣相比於角度-軸表示的向量旋轉操作，能節省超過 61% 的計算量[6]。

進一步評論，最近有關人體方位估算的研究集中在提高估算算法的準確性和穩健性。例如，We 等人提出的 MeBoW 系統[7] 結合了2D姿勢估算與單眼深度估算，以準確估算三維人體姿勢和方位。Zhou 等人[8] 則提出了一種關節迴歸方法，使用2D關節位置和深度圖來準確估算人體方位。總結來說，基於四元數的方法相較於角度-軸表示具有優勢，而近期的研究則著重於提高人體方位估算算法的準確性和穩健性。此外，硬體技術的進步使得在邊緣設備上有效執行複雜計算成為可能。因此，未來的人體方位估算研究應考慮這些技術進展，以改善算法的性能和效率。


## III. 概念理論與實現方法論

### A. 概述

本方法所面臨的挑戰在於實現演算法解決方案，以尋找引言段落中提到的輸入。首先，計算人體姿態物體方位的問題伴隨著定位身體標誌點的延遲標準的可接受性。接下來，是設計一個數學函數，從這些點的姿態數據中提取四元數。本演算法的新穎之處在於其能夠從人類在圖像中的二維圖像中推導出姿態四元數。

為了解決方位估算的問題，我們採用了 MediaPipe，這是一個由 Alphabet Inc. 提供的框架，能夠部署從深度學習模型訓練而來的人體姿態物體檢測解決方案。該套件旨在資源利用率低的邊緣設備上運行[9]。雖然該框架實現了令人欽佩的檢測延遲，但在轉移到需要生成四元數的應用場景（如機器人導航[10]等）時，系統存在固有缺陷，因為其基於三維笛卡爾空間。這種新穎演算法提供的一個附加優勢是，即使在動態參考框架上實施，如移動中的移動機器人，模型的可移植性仍能得到維持。

此時必須注意，僅考慮單一標量值（如方位）並未擴展工具的範圍。對於自動駕駛車輛，沒有人會考慮如此詳細的骨架追蹤器，而是會使用一個同時能從 RGB 圖像中獲取物體方位的深度物體檢測器。另一方面，如果涉及人機協作場景，則擁有詳細的骨架追蹤器和人體姿態預測是一個有價值的工具。

### B. 四元數轉換

在我們介紹構成新穎演算法的方程式之前，理解為何在此應用中需要四元數是很重要的。我們可以通過以下例子來可視化這一點：行人阻擋自動駕駛車輛或機器人的情況。對於需要機器人迅速響應場景中重大臨時變化的情況，尤其是那些可能危及人類生命的情況，如人類橫越移動車輛的路徑，四元數可以被計算出來，以估算人體姿態中任意相鄰關節對的方位。

基於此，我們將演算法的使用案例縮小到行人方位檢測問題，並根據此建模我們的實現。因此，我們選擇用於評估目標人類姿態的兩個點是肩膀點，因為其相對位置能準確描述該目標的方位[11]。相同的方程式和思維過程可以用來提取任何關節對的數據。

![[PaperWithCode/9-quaternion-extraction/Figure2.png]]
圖 2. 作為 COCO（綠色）超集的人體骨骼的 BlazePose 33 關鍵點拓樸 [12]

為了縮小這一選擇範圍，我們評估了 MediaPipe 姿態解決方案文檔中所有提供的選項[12]，以選擇那些在目標的滾轉、俯仰或偏航變化時，其投影在二維畫面上肯定會改變位置的適當點對。此外，我們還任意確定這些點在身體中線上必須保持對稱，因為考慮到我們實現的潛在使用案例，這似乎是一個直觀的指導原則。在從框架估算的笛卡爾空間中獲取這些點的坐標後，通過取上述兩個肩膀點的坐標生成骨架的旋轉矩陣。設左肩和右肩點在畫面上的坐標分別為 (xl, yl, zl) 和 (xr, yr, zr)。因此，旋轉矩陣的 Z 軸向量可以使用兩點之間的差值計算如下：

$$\vec{z}=\begin{bmatrix}xl&yl&zl\end{bmatrix}-\begin{bmatrix}xr&yr&zr\end{bmatrix} \tag{1}$$

$$\widehat{z}=\left\{\begin{matrix}\frac{\vec{z}}{|\vec{z}|}; \Delta z\neq0\\\begin{bmatrix}0&-1&0\end{bmatrix}; \Delta z=0\end{matrix}\right. \tag{2}$$
類似地，X 和 Y 軸向量生成如下：

$$\widehat{x}=\begin{bmatrix}0&0&1\end{bmatrix}\times\widehat{z};iff\widehat{x}\neq0else\begin{bmatrix}1&0&0\end{bmatrix} \tag{3}$$

$$\widehat{y}=\widehat{z}\times\widehat{x} \tag{4}$$

這使我們能夠使用相機觀察方法[14]推導出旋轉矩陣 [13]：

$$R_{3,3}=\begin{bmatrix}r_{00}&r_{01}&r_{02}\\r_{10}&r_{11}&r_{12}\\r_{20}&r_{21}&r_{22}\end{bmatrix}=\begin{bmatrix}\widehat{x}&\widehat{y}&\widehat{z}\end{bmatrix} \tag{5}$$

隨後，從這個旋轉矩陣中以標準形式獲得四元數 Q [13]：

$$
Q = a + bi + cj + dk \quad \tag{6}
$$

其中，係數值可以根據方程式 7 至 10 映射[15]：

$$a=\frac12\sqrt{|1+r_{00}+r_{11}+r_{22}|} \tag{7}$$

$$
b = \frac{r_{21} - r_{12}}{4a} \quad \tag{8}
$$

$$
c = \frac{r_{02} - r_{20}}{4a} \quad \tag{9}
$$

$$
d = \frac{r_{10} - r_{01}}{4a} \quad \tag{10}
$$

為了從這些方程中提取可用的現實世界統計數據並測試新穎演算法的實用性，我們通過對獲取的四元數應用某些轉換來提取人體姿態物體在相機畫面中面對的方向（此處稱為人體姿態物體的方位角）。此時需要注意的是，返回的四元數值確實包含一些噪聲，這是由於 xl、yl、zl、xr、yr 和 zr 的隱式測量不確定性所致（參見第 IV 節，子節 D）。這些不確定性通過實施一維卡爾曼濾波器來補償，以對人體姿態物體的方位角進行過濾，因為這在測試後被發現是最準確的方法。

這是通過從四元數的角度-軸形式中提取旋轉角度來完成的，因為旋轉矩陣從模型中提取時，軸向量本身被隱式地設置為從畫面中人類物體的頭部向上定向。

假設我們的四元數形式為：

$$
Q = \cos\theta + \sin\theta(xi + yj + zk) \quad \tag{11}
$$

則 theta 的提取公式為：

$$
\theta = \arccos\left( \frac{a}{\sqrt{a^2 + b^2 + c^2 + d^2}} \right) \quad \tag{12}
$$

然後，theta 被轉換以獲得我們參考框架中的方位角，這樣參考軸就是橫跨相機畫面窗口的水平軸。

$$\theta=\frac{\theta\cdot\frac{180^2}{\pi}}{45}-180 \tag{13}$$

此處應用的轉換處理了從弧度到度的轉換，以及四元數中的 x 度旋轉在現實生活情境中轉換為 2x 度旋轉的事實。該方程是在收集了人體物體 180 度旋轉的 theta 值並將其映射到同一物體面對的現實世界角度後得出的。計算的角度本質上是從連接肩膀點的線到相機畫面水平線的垂直線所包含的角度。這一場景可以如圖 3 所示進行可視化，未考慮相機和肩膀點不在同一高度的事實。

![[PaperWithCode/9-quaternion-extraction/Figure3.png]]
圖 3.僅採用肩部點來偵測行人物體方向角的用例的簡單視覺化。

### C. 演算法

在討論主要演算法之前，請注意 `getRotationMatrix` 函數接受 6 個浮點值，分別表示 \(xl\)、\(yl\)、\(zl\)、\(xr\)、\(yr\) 和 \(zr\)（參見方程式 1），並通過迭代方程式 2 到 4 中的計算，返回方程式 5 中的旋轉矩陣。而 `calculateQuaternion` 函數接受一個旋轉矩陣 \(R\)（如方程式 5 所示），根據方程式 7 到 10 計算其分量，進而計算出四元數 \(Q\)（如方程式 6 所示）。

從骨架姿勢的二維圖像生成四元數的整體算法流程設計如下：

![[PaperWithCode/9-quaternion-extraction/Algorithm.png]]

## IV. 結果與支持統計數據

本系統使用標準廣角 USB 2.0 攝影機進行測試（具體規格詳見子節 C），平均幀率為 24 幀每秒。取幀率的倒數可得整個演算法的測試延遲，該值為 41.67 毫秒。將此方法與具有三層二十個神經元的基本人工神經網絡進行比較，從數學運算次數的角度來看，該方法展現了其優勢，尤其是神經網絡目前是此類任務的行業標準[18]。

圖 4 展示了執行序列的快照，其中得到的四元數 \(Q = 0.63 - 0.12i + 0.31j + 0.62k\)，如圖 4 所示。該結果的準確性已在子節 B "模型準確性驗證" 中進行驗證。本節中的所有結果均來自對該演算法進行 25 次測試迭代後，認為滿意時所得的數據。

![[PaperWithCode/9-quaternion-extraction/Figure4.png]]
圖 4. 使用新穎演算法從姿態中提取四元數的演示。

從單一單眼攝影機提取人體方位的演算法顯示出其效率，延遲為 41.67 毫秒，幀率為 24 幀每秒。然而，若沒有來自雷射掃描儀或運行適當圖像處理算法的立體攝影機的進一步讀數，準確性難以評估，因為四元數需轉換為人類可讀取的量（例如方位角）。

我們提取了方位角並與實際數據進行比較，該演算法能夠準確地確定畫面中人體物體視線與地平線之間的角度，誤差常為正負 5 度。同樣的結果也出現在取垂直於目標人體中線的角度與畫面垂直線的比較中，進一步確認該系統在三維中的準確性。此演算法測試涵蓋了平面上所有可能的運動方向，詳細內容見子節 A。

關於數學運算量的比較，除了智能交通系統的實現場景外，難以評估該比較的相關性。然而，近期有數篇研究提出了基於深度神經網絡的方法來完成同樣的任務，並取得了有希望的結果。例如，Yan 等人提出了一種基於深度神經網絡的方法，從單眼圖像中估算人體姿勢和方位，平均延遲為 100 毫秒，準確率為 92.8%[19]。Mehta 等人則提出了一個端到端深度學習框架，從單一圖像中估算三維姿勢和形狀，在多個基準數據集上達到了最先進的性能[20]。

A. 測試條件  
根據作者的說明，測試此新穎演算法所選的場景旨在反映系統的預期使用情境，即從自動機器人或車輛的視角估算行人體的方位角。因此，這些場景包含多個人類物體，以展示由於演算法單線程性質，能夠任意選擇具有最高信心值的骨架框架。

行人體的運動方向角度域維持在 10 度到 180 度之間，通過外推行人體在畫面上的運動方向，將其分類為模糊狀態。

B. 模型準確性驗證  
由於當前資源限制，提取人體姿態物體的方位角以驗證四元數模型的準確性，通過交叉檢查用戶所面對的角度（見方程式 11 到 13）。請注意，演算法中所有計算只需檢測到姿態物體本身和肩膀標誌點即可。

C. 系統規格  
本系統在以下平台上進行測試：
- Intel Core i5 7200U 處理器
- 8GB RAM
- 512 GB 固態硬碟
- 外接 USB 2.0 30 幀每秒 2MP「Passport」攝影機，解析度 1920x1080，視角 110 度。

D. 卡爾曼濾波器消除四元數噪聲  
為了獲得子節 B 中提到的方位角，對 theta 讀數應用了單維卡爾曼濾波器，以獲得穩定的輸出[21]。

重申一下，角度測量值按照等式13 中給出的方式進行轉換，以考慮到所有θ 值都是相對於水平平分框架的軸獲取的這一事實，這是透過採用人體姿勢對象的測試案例來有效實現的直立姿勢。請參閱圖 6 以了解其視覺化效果。

濾波器設計為動態，用於假設系統完美的情況下，即預測協方差方程假設模型不確定性為零。這是因為系統的隨機性質，且沒有可行的物理方程能準確定義姿態物體的運動。因此，當實際測量不可靠時，濾波器接受窗口中最近 10 次讀數的平均值作為預測。系統每秒從生成的四元數中計算 24 次測量值。方程式 14 到 16 描述了卡爾曼增益、狀態和協方差的更新，其中 \(k\) 是卡爾曼增益，\(p\) 是協方差，\(r\) 是角度測量不確定性（經測試後實驗確定為 0.5），\(x\) 是前一次測量，\(z\) 是當前測量。

$$
k = \frac{p}{p + r} \quad ; \quad \text{kalman gain calculation} \quad \tag{14}
$$

$$
x = x + k(z − x) \quad ; \quad \text{state updation} \quad \tag{15}
$$

$$
p = (1 − k)p \quad ; \quad \text{covariance updation} \quad \tag{16}
$$

為了展示此系統在現實世界使用案例中的轉化，我們選擇建立一個行人意圖分類系統的初步原型[22]，該系統記錄畫面中行人體物體的坐標，並將前述 theta 輸出值記錄在一個數據窗口中，以預測未來的運動路徑。分類是使用模糊狀態方法來考慮這些輸入。圖 6 展示了該分類的示範，其中需要注意的是右上角疊加讀數中的第三個值 172.04。這是新穎演算法在實地測試中返回的行人體物體的方位角。這可以通過視覺上驗證參考行人體物體幾乎垂直橫越機器人預測路徑來確認。還需要注意的是，這裡的圖像被水平翻轉，因此乍看之下似乎與先前提到的畫面分割軸定義不一致。

意圖分類器能夠準確分類出畫面中行人體物體的約 75% 坐標，在 2 秒內預測未來運動方向，並且準確半徑為 50 像素。

![[PaperWithCode/9-quaternion-extraction/Figure5.png]]
圖 5. θ 測量濾波值的折線圖表示，此處稱為 realAngle。

![[PaperWithCode/9-quaternion-extraction/Figure6.png]]
圖 6. 從地面車輛角度實現的模糊行人意圖分類演算法原型的演示，以演示從包含人體骨骼姿勢物件的 2-D 相機幀中提取四元數的實用性。

## V. 結論與結尾

因此，結論認為該新穎演算法適合使用二維攝影機提取人體物體的姿勢，並滿足由於硬體使用最小化而節省成本的要求，以及在延遲和性能方面的要求。該演算法可以在硬體上實現[23]，並且在合理的準確度範圍內運行。儘管如此，由於其單線程性質以及低計算資源使用，使其適合於邊緣部署應用，然而需要注意的是，所需的執行緒數量隨著檢測到的姿勢物體數量線性增加。

A. 優化與未來展望  
該新穎演算法可以通過多種方式進行優化，主要方法是多線程處理視訊串流，以及實現多個人體物體的檢測和並行處理其姿勢估算[24]。在擴展第四節子節 A「測試條件」中提到的使用案例時，該模型可以用來實現一個更詳盡的行人意圖分類器（如該節子節 D 中所展示），從而更可靠地預測行人體物體是否會穿越自動機器人或車輛的路徑，進而可能危及生命[25]。

除了優化演算法之外，使用 GPU 的多核心數量也展現了有前景的應用前景[26]。當前，開發能夠充分利用這些強大設備潛力的演算法需求日益增長。然而，要確切得出結論，還需要進行更深入的文獻調查。探討與 GPU 計算相關的限制與挑戰以及如何克服它們以實現最佳性能是重要的課題。