以下是 SMIE 這篇論文的重點整理：

### **1. 摘要**
- **目標**：零樣本基於骨架的動作識別，旨在識別未見過的動作類別。
- **問題**：
  - 全局視覺/語義分佈的對齊被忽略。
  - 忽略了動作的時間信息。
- **解決方案**：提出了一種基於互信息估計和最大化的框架 (SMIE)，通過對齊視覺和語義空間，並利用時間信息來提高識別性能。
結合了從骨架資料中提取的視覺特徵（ST-GCN)和從類別描述中提取的語義特徵(Sentence-BERT)。這種結合有助於模型在沒有直接樣本的情況下識別新的動作類別。
  
### **2. 方法概述**
- **架構**：SMIE 包含兩個模塊：
  1. **全局對齊模塊**：透過最大化視覺空間和語義空間之間的互信息來對齊這兩個空間。使用基於Jensen-Shannon散度（JSD）的估計器來最大化配對視覺和語義特徵之間的互信息。
  2. **時間約束模塊**：利用動作中的時間信息來捕捉更詳細的動態變化，提升識別能力。
  
### **3. 全局對齊模塊**
- 模組的設計：
	為了解決這個問題，提出了全局對齊模組，該模組透過最大化視覺特徵（V）和語義特徵（A）之間的互資訊（$I(V; A)$）來學習估計網路（$T $）。
- 互資訊的計算：
	互資訊的計算利用了KL散度（KL-divergence）來衡量聯合分佈和邊緣分佈乘積之間的差異，以此來捕捉視覺和語義特徵之間的共享資訊。
- 互資訊的表示：
	互資訊可以用聯合熵和條件熵來表示，最大化互資訊等同於最大化聯合熵與條件熵之間的差異。
- 估計網路的建構：
	利用互資訊將視覺和語義特徵編碼為緊湊的分佈式向量表示，並透過連接網路從資料中學習這些表示。
- Jensen-Shannon散度（JSD）的應用：
	由於直接計算高維空間中兩個隨機變數的互資訊非常困難，因此受到Jensen-Shannon散度的啟發，提出了一個學習估計網絡，該網絡將全局視覺特徵和語義特徵作為輸入，並輸出兩者之間的相似度分數。
- 對比學習的運用：
	透過對比學習，將正樣本對（配對的視覺/語義特徵）和負樣本對（未配對的視覺特徵和語義特徵）送入估計網絡，以此來訓練網絡並最大化互資訊的近似估計器。
- 損失函數的定義：
	為了最大化全域對齊的估計互信息，定義了損失函數 $\mathcal{L}_{1}$，並在訓練過程中透過梯度下降更新估計網路的參數。

  
### **4. 時間約束模塊**

- 動作序列的時間動態資訊：
	3D 骨架資料包含了時間維度，使得動作辨識問題更為複雜。動作序列中的每一幀都包含了時間訊息，而關鍵影格中包含的資訊對於區分不同動作類別尤其重要。
- 計算雙向運動注意力：
	透過計算骨架序列中每一幀之間的時間位移來獲取運動資訊。利用後續影格與目前影格之間的差異（$p^{\text{nex}}{k,j,c}$）以及目前影格與前一格之間的差異（$p^{\text{pre }}{k,j,c}$）來定義序列的雙向運動。
- 關鍵影格的選擇：
	計算每一幀的平均運動值，以此作為幀的注意力權重。選擇具有最高注意力分數的前P幀作為關鍵幀，這些幀被認為包含更多區分資訊。
- 建構注意力掩蔽樣本：
	將關鍵影格從原始骨架序列中掩蔽，建立帶有資訊遺失的注意力掩蔽樣本序列。
	使用視覺特徵提取器和層歸一化層提取時間約束視覺特徵，並與對應的語義特徵拼接，形成時間約束的正樣本對。
- 時間約束互資訊的最大化：
	利用Jensen-Shannon散度（JSD）估計器來最大化時間約束視覺特徵和對應語意特徵之間的互資訊。
	透過鉸鏈損失（hinge loss）確保全局互資訊大於時間約束互資訊，以此來正規化模型。
- 損失函數：
	最終的損失函數結合了全域互資訊最大化項和時間限制項，透過權衡參數λ來平衡兩者。
