

## 摘要
在3D人體動作識別中，有限的監督數據使得充分挖掘強大網絡（如transformer）的建模潛力變得具有挑戰性。因此，研究人員一直積極探索有效的自我監督預訓練策略。在本研究中，我們展示了，相較於目前主流的預訓練任務如人體關節的掩碼自我組件重建，顯式的上下文運動建模才是學習3D動作識別的有效特徵表示的關鍵。具體而言，我們提出了Masked Motion Prediction（MAMP）框架。具體來說，MAMP框架以被掩碼的時空骨架序列為輸入，並預測對應的被掩碼人體關節的時間運動。考慮到骨架序列的高時間冗餘性，在我們的MAMP框架中，運動信息也充當了一個經驗性的語義豐富性先驗，指導掩碼過程，從而促進對語義豐富的時間區域進行更好的關注。廣泛的實驗結果表明，在NTU-60、NTU-120和PKU-MMD數據集上，所提出的MAMP預訓練框架顯著提升了採用的vanilla transformer的性能，並在不使用任何花哨技巧的情況下達到了最先進的結果。我們的MAMP源代碼可在以下鏈接獲取：https://github.com/maoyunyao/MAMP。

## 1. 介紹

如何準確識別人體動作一直是計算機視覺領域的長期挑戰。隨著深度感測技術和姿態估計技術的進步 [3,16,54] , 骨架為基礎的3D人體動作識別已成為一個新興的問題，並在一系列應用中具有重要意義，如人機互動、視頻監控、虛擬現實等。儘管骨架資料具有計算效率高、背景魯棒性強等優點，但現有的監督式3D動作識別方法 [5,7,14,19,24,25,32,39,42,43,60] 過度依賴精心標註的訓練序列，而這些序列的獲取成本高且耗時。此外，有限的監督數據也會導致通用模型，特別是帶有較弱歸納偏置和高模型容量的transformers，過度擬合的問題。這些事實促使人們探索自我監督的3D動作表徵學習方法。

在文獻中，最早針對圖像開發的流行預訓練任務已被適應於3D動作表徵學習，如顏色化 [58] 、重建 [62,46,27] 、對比學習 [23,48,49] 等。其中，對比學習曾憑藉其簡潔的框架和優異的性能在3D動作表徵學習中占據主導地位。然而，作為一種全局表徵學習方法，它仍面臨某些限制，例如在時間上下文建模方面缺乏顯式約束，並且過於依賴啟發式的動作數據增強 [31] ，這阻礙了對3D動作的進一步探索。

隨著transformers在計算機視覺領域的蓬勃發展，掩碼自編碼器（MAE） [17] 因其卓越的性能引起了大量研究的興趣。考慮到3D骨架是人類行為的抽象表示，越來越多的研究開始將MAE概念應用於3D動作表徵學習，以捕捉骨架序列的潛在時空動態。早期的嘗試通常遵循圖像的做法，採用人體關節的掩碼自我重建作為預訓練任務。儘管已經付出了相當多的努力，我們認為，這樣的自我重建目標無法有效地引導網絡優先進行上下文運動建模，然而，對於理解3D動作來說，上下文運動建模至關重要，因為在骨架數據中外觀信息已大大減少。因此，如何更好地在自我監督的3D動作表徵學習中探索上下文運動線索是一個重要問題。

基於這一想法，我們提出了**Masked Motion Prediction（MAMP）**，這是一個簡單但有效的框架來解決自我監督的3D動作表徵學習問題。具體來說，MAMP以被掩碼的時空骨架序列為輸入，並預測對應的被掩碼人體關節的時間運動。通過這種方式，網絡被直接引導進行上下文運動建模。此外，根據我們的觀察，具有顯著運動的時刻對於理解人體動作通常是關鍵的，因此，在我們的MAMP中，時間運動不僅作為預訓練目標，還作為一個經驗性的語義豐富性先驗，有效地指導骨架掩碼過程。與隨機版本相比，所提出的運動感知掩碼策略將額外的時間運動強度作為輸入，首先將輸入的強度轉換為概率分佈，然後利用重參數化技術進行高效的概率引導掩碼樣本選取。因此，具有顯著運動的關節以較高的概率被掩碼，從而促進對語義豐富的時間區域進行更好的關注。

如圖1所示，與人體關節的掩碼自我重建相比，掩碼運動預測作為一個更有效的預訓練任務，大大減輕了由於註釋有限的3D骨架資料，transformers無法充分發揮其建模潛力的問題。在MAMP預訓練後，所採用的vanilla transformer在3D動作識別中創下了一系列的最先進記錄，並且不需要使用多流集成等花哨技巧。具體而言，與從零開始訓練相比，我們的MAMP在挑戰性的NTU RGB+D 60 [38] 和NTU RGB+D 120 [28] 數據集的跨主體協議中，分別實現了10.0%和13.2%的顯著絕對性能提升，分別達到93.1%和90.0%的top-1準確率。我們希望這個簡單但有效的框架能成為一個強大的基線，促進未來在3D動作預訓練及其他領域的研究。

總體來說，我們做出了三個方面的貢獻：
- 我們提出了掩碼運動預測來學習3D動作表徵，從根本上減輕了傳統掩碼自我重建範式中上下文運動建模不足的問題。
- 我們設計了運動感知掩碼策略，將運動強度作為語義豐富性先驗，實現自適應關節掩碼。
- 我們在三個流行的基準數據集上進行了廣泛的實驗，驗證了我們方法的有效性。值得注意的是，我們的MAMP使得vanilla transformer首次實現了3D動作識別中的最佳性能。

![[PaperWithCode/17-MAMP/Figure1.png]]
圖1. (a) 掩蔽自動編碼器(MAE) 和我們的掩蔽運動預測器(MAMP) 之間的預訓練客觀比較以及(b) 典型MAE 方法（即SkeletonMAE [53]）和我們的MAMP 之間的性能比較的圖示根據線性評估協議。

## 2. 相關工作

### 2.1. 監督式 3D 動作識別
如何更好地對動態骨架進行建模以進行監督式動作識別，是一個被廣泛研究的問題。在許多早期的研究中，RNNs 因其出色的序列建模能力而備受青睞，如 [14] 提出的層次化 RNN 模型以及 [30, 29] 中的 2D 時空 LSTM。鑑於 CNNs [21, 18] 在圖像理解方面的巨大成功，一些方法也試圖將其應用於 3D 動作識別。為了適應輸入格式， [13, 22] 將骨架序列視為三通道的偽圖像（x、y 和 z 坐標），並將幀數和關節數分別作為圖像的高度和寬度。考慮到關節之間的自然連接，ST-GCN [55] 引入了用於骨架建模的圖神經網絡（GCNs），其中卷積核根據骨架的拓撲精心設計。ST-GCN 的出色性能引領了基於 GCN 的 3D 動作識別的潮流，隨後出現了許多改進，如輸入流 [51, 26, 40] 、卷積核設計 [5, 61, 39, 32] 等。

最近的一些方法 [36, 35, 41] 試圖將流行的視覺 transformer 引入 3D 動作識別。然而，在有限的訓練數據下，帶有較弱歸納偏置的 vanilla transformers 無法得到充分訓練。因此，現有的監督式嘗試中需要許多定制設計，如時間卷積 [36] 、圖卷積 [35, 36] 、時空分離 [41] 等。在我們的方法中，我們證明了通過掩碼運動預測進行預訓練是 transformers 在 3D 動作識別中成功的關鍵。所提出的 MAMP 框架賦予了 vanilla transformer 無與倫比的性能。

### 2.2. 自我監督的 3D 動作識別
自我監督的表徵學習旨在從未標記的數據中捕捉領域先驗，以促進模型在下游任務中的應用。在 3D 人體動作識別中，許多預訓練任務已經被用來探索存在於骨架序列中的動作上下文。其中，LongT GAN [62] 和 P&C [46] 試圖通過基於自編碼器的序列重建來學習 3D 動作表徵，其中 P&C 中的解碼器被進一步弱化，以促進特徵編碼器的學習。在 Colorization [58] 中，骨架序列被視為點雲，並通過基於其空間和時間順序對每個關節進行著色來學習動作表徵。

最近，許多基於對比學習的方法 [27, 48, 23, 49, 59, 34] 紛紛出現，展示了相較於早期工作更優越的性能。為了學習更好的 3D 動作表徵，它們要麼試圖在不同的骨架模態之間挖掘有用的監督信息 [23, 34] ，要麼探索更好的動作數據增強 [49] 和正樣本挖掘策略 [59] 。然而，作為一種最初設計用於圖像的全局特徵學習方法，對比學習缺乏對時間運動上下文的明確約束，限制了其在 3D 動作領域的進一步發展。

SkeletonMAE [53] 首次將 MAE [17] 的概念引入 transformer 基於的 3D 動作表徵學習中，並預測被掩碼區域的原始關節坐標。在我們的方法中，我們證明這樣的自我重建目標在學習 3D 動作表徵時是次優的。因此，我們引入了 Masked Motion Prediction（MAMP）框架，以進行顯式的上下文運動建模，從而顯著提高了相較於原始骨架重建的性能。

### 2.3. 掩碼視覺預測
隨著視覺 transformers [4, 12, 50] 的發展，來自自編碼器 [1] 的掩碼預測再次復興。類似於 NLP 中 BERT [11] 的預訓練，輸入標記被隨機掩碼並預測相應的目標，這些目標可以是原始像素 [17] 、HOG 特徵 [52] 或從離線學習的 dVAEs 中提取的標記 ID [2] 。最近，也有一些嘗試 [45, 57] 將光流或圖像的時間差作為輔助重建目標，但當單獨應用時，性能表現不佳。這主要歸因於原始圖像的高度冗餘性，其中難以準確提取關鍵的前景運動。

在我們的方法中，我們採用掩碼視覺預測的概念來進行 3D 動作表徵學習，並將時間骨架運動作為唯一的重建目標。與圖像不同，人體骨架序列中的關節具有顯式的時間對應關係，能夠輕鬆提取其準確的運動上下文。此外，我們還將運動強度作為語義豐富性的先驗，指導掩碼過程。

### 3. 方法

#### 3.1. 概述

圖 2 展示了我們提出的 Masked Motion Prediction (MAMP) 框架的整體流程。該框架的輸入是一個骨架序列$S \in \mathbb{R}^{T_s \times V \times C_s}$，其中從原始數據中隨機裁剪一部分並調整為固定的時間長度$T_s$。$V$和$C_s$分別表示關節數和坐標通道數。輸入的運動序列$M \in \mathbb{R}^{T_s \times V \times C_s}$也會被提取出來，並通過對時間維度的差分來定義（對第一幀手動填充）。

和大多數視覺 transformers 一樣，輸入的關節被線性映射為關節嵌入$E \in \mathbb{R}^{T_e \times V \times C_e}$。接下來，應用運動感知掩碼策略，在時間運動強度的指導下，掩蓋大部分的嵌入特徵。剩餘的特徵通過編碼器-解碼器架構處理，其中 transformer 編碼器從未掩蓋的關節嵌入中學習表示，transformer 解碼器根據可學習的掩碼標記和編碼器中的潛在表示進行上下文建模。與 MAE [17] 重建原始信號以進行表示學習不同，在 MAMP 中，採用了一個運動預測頭，該頭使用解碼的特徵作為輸入，預測輸入骨架序列的時間運動。

經過上述預訓練後，僅保留關節嵌入層和 transformer 編碼器以供下游應用使用。

![[PaperWithCode/17-MAMP/Figure2.png]]
圖 2. 所提出的 MAMP 架構的整體流程。與先前的工作 [62, 53] 中採用的自重建方案不同，我們的 MAMP 透過預測屏蔽關節輸入的相應運動序列來學習 3D 動作表示。此外，運動資訊也作為經驗語意豐富性先驗，有效指導掩蔽過程，使更多的注意力能夠應用於具有顯著時間運動強度的區域。
#### 3.2. 關節嵌入

在大多數基於 transformer 的方法 [35, 41, 36] 中，每個時空骨架關節是分開嵌入的，這導致了大量的輸入標記。考慮到時間冗餘性，在我們的方法中，輸入骨架序列$S \in \mathbb{R}^{T_s \times V \times C_s}$被分割成無重疊的時間段$S' \in \mathbb{R}^{T_e \times V \times l \times C_s}$，其中$l$是每段的長度，$T_e = T_s / l$。在每個時間段內，具有相同空間位置的關節一起嵌入：
$$
E = \text{JointEmbed}(S') \in \mathbb{R}^{T_e \times V \times C_e}, \tag{1}
$$
其中$C_e$是嵌入特徵的維度。與原始骨架序列相比，嵌入$E$的時間解析度降低了$l$倍，提高了計算效率。

#### 3.3. 運動提取

與具有高空間冗餘的 RGB 幀不同，人體骨架序列具有高度語義化，並且在相鄰幀之間有明確的對應。因此，我們可以通過對關節坐標應用時間差分輕鬆獲取其運動$M \in \mathbb{R}^{T_s \times V \times C_s}$：
$$
M_{i,:,:} = S_{i,:,:} - S_{i-m,:,:}, \quad i \in m, m+1, \dots, T_s - 1, \tag{2}
$$
其中步長$m$控制運動的步幅。為了方便，運動序列會根據原始輸入的長度進行填充：
$$
M_{0:m-1,:,:} = \begin{cases} 0, & \text{constant}, \\ M_{m:2m-1,:,:}, & \text{replicate}. \end{cases} \tag{3}
$$
其中$constant$和$replicate$分別表示常數填充（用零）和複製填充。

#### 3.4. 運動感知掩碼

在我們的方法中，運動信息不僅作為預訓練期間的重建目標，還作為指導嵌入特徵掩碼的語義豐富性先驗。考慮到骨架序列以長度為$l$的段進行嵌入，我們提取運動序列$M^{\text{mask}} \in \mathbb{R}^{T_e \times V \times C_i}$，並根據式 (2) 和式 (3) 使用步長$m = l$和複製填充，將其進一步重塑為$M' \in \mathbb{R}^{T_e \times V \times l \times C_i}$。接著，計算運動強度$I$，它表示每個時空段的運動重要性：
$$
I = \sum_{i=0}^{l} \sum_{j=0}^{C_i} |M'_{:,:,i,j}| \in \mathbb{R}^{T_e \times V}. \tag{4}
$$
由於人類動作由一系列時間運動組成，我們認為運動強度在很大程度上反映了語義的豐富性。因此，在 MAMP 中，運動強度被進一步轉換為帶有溫度超參數$\tau$的概率分佈：
$$
\pi = \text{Softmax}(I / \tau), \tag{5}
$$
這表示每個嵌入特徵被掩蓋的概率。MAMP 中，採用 gumble max 方法進行高效的概率指導掩碼索引抽樣：
$$g=-\log(-\log\epsilon), \epsilon\in U[0,1]^{T_e\times V},$$
$$idx^{\mathrm{mask}}=\text{Index-of-Top-K}(\log\pi+g), \tag{6}$$
其中$U[0, 1]$表示 0 和 1 之間的均勻分佈。得到的$\text{idx}^{\text{mask}}$指示哪些關節被掩蓋，並用於選擇未掩蓋的標記（見第 3.5 節）。基於上述操作，網絡被鼓勵更關注語義豐富的區域，從而學習更具辨別性的 3D 動作表徵。

#### 3.5. 掩碼運動預測

我們遵循 MAE [17] 的編碼器-解碼器設計，編碼器專注於表徵學習，而解碼器則負責實現預訓練預設目標。

- **編碼器：** 在編碼器中，分別將時空位置嵌入$P_{e}^{s} \in \mathbb{R}^{1 \times V \times C_e}$和$P_{e}^{t} \in \mathbb{R}^{T_e \times 1 \times C_e}$元素相加到輸入的關節嵌入$E$中：
$$
E_p = E + P_{e}^{s} + P_{e}^{t}.
$$
然後，根據式 (6) 中提取的 $\text{idx}^{\text{mask}}$ 選擇 $E_p$ 中的未掩蓋標記，並展平成 $E_p^u \in \mathbb{R}^{N_u \times C_e}$，其中 $N_u = T_e \times V \times (1 - \text{mask ratio})$ 表示未掩蓋的標記數。隨後，通過 $L_e$ vanilla transformer 塊提取潛在表徵：
$$
H_0 = E_p^u, 
$$
$$
H'_l = \text{MSA}(\text{LN}(H_{l-1})) + H_{l-1}, \quad l \in 1, \cdots, L_e,
$$
$$
H_l = \text{MLP}(\text{LN}(H'_l)) + H'_l, \quad l \in 1, \cdots, L_e,
$$
$$
H_e^u = \text{LN}(H_{L_e}),
$$
其中 $MSA$、$MLP$ 和 $LN$ 分別表示多頭自注意力、全連接層和層正規化。

- **解碼器：** 在解碼器中，可學習的掩碼標記插入 $H_e^u$ 中，根據掩碼索引 $\text{idx}^{\text{mask}}$ 重塑為 $H_e \in \mathbb{R}^{T_e \times V \times C_e}$，經過 $L_d$ 個解碼器層進行掩碼建模：
$$
Z_0 = H_e + P_d^s + P_d^t,
$$
$$
Z'_l = \text{MSA}(\text{LN}(Z_{l-1})) + Z_{l-1}, \quad l \in 1, \cdots, L_d,
$$
$$
Z_l = \text{MLP}(\text{LN}(Z'_l)) + Z'_l, \quad l \in 1, \cdots, L_d,
$$
$$
Z_d = \text{LN}(Z_{L_d}),
$$
其中 $P_d^s$ 和 $P_d^t$ 分別是 transformer 解碼器的空間和時間位置嵌入。

- **運動預測：** 在我們的方法中，重建目標不是原始骨架，而是根據式 (2) 和式 (3) 預先提取的運動序列 $M_{\text{target}}$，並根據其段內均值和標準差進行標準化。因此，給定解碼特徵 $Z_d \in \mathbb{R}^{T_e \times V \times C_d}$，我們額外採用預測頭來預測被掩蓋關節的時間運動：
$$
M^{\text{pred}} = \text{MotionPredHead}(Z_d),
$$
我們經驗發現一個簡單的全連接層效果良好。對於被掩蓋的關節，我們計算預測結果 $M^{\text{pred}}$ 與重建目標 $M^{\text{target}}$ 之間的均方誤差（MSE）：
$$
L = \frac{1}{|\text{idx}^{\text{mask}}|} \sum_{(i,j) \in \text{idx}_{\text{mask}}} \|M_{i,j,:}^{\text{pred}} - M_{i,j,:}^{\text{target}}\|_2^2.
$$

## 4. 實驗

### 4.1. 數據集與評估協議

**NTU-RGB+D 60 [38]**:  
NTU-RGB+D 60（簡稱 NTU-60）是一個大規模的人體動作識別數據集。該數據集包含 60 種動作類別，由 40 位不同的受試者執行，共有 56,880 條 3D 骨架序列。在本文中，我們採用了作者推薦的評估協議，即交叉受試者 (X-sub) 和交叉視角 (X-view)。其中，X-sub 使用 40 位受試者中一半的人執行的動作序列作為訓練樣本，剩餘的一半作為測試樣本；X-view 的訓練樣本是由攝像機 2 和 3 拍攝的動作序列，測試樣本則是由攝像機 1 拍攝的序列。

**NTU-RGB+D 120 [28]**:  
NTU-RGB+D 120（簡稱 NTU-120）是 NTU-60 的擴展版本，其中動作類別的數量從 60 增加到了 120，總骨架序列數量和受試者數量分別增加到了 114,480 和 106。此外，作者還引入了一個更具挑戰性的評估協議，名為交叉設置 (X-set)，以取代 NTU-60 中的 X-view。具體來說，X-set 根據攝像機的距離和背景將序列分為 32 個不同的設置。這些設置中一半的樣本用作訓練集，另一半則作為測試集。

**PKU-MMD [9]**:  
按照 [48] 中的描述，為了在 PKU-MMD 上進行 3D 動作分類，我們根據時間標註裁剪出動作實例，並根據交叉受試者協議將其分為訓練集和測試集。PKU-MMD 包含兩個階段：PKU-MMD I（PKU-I）和 PKU-MMD II（PKU-II）。在 PKU-I 中，訓練集和測試集的樣本數分別為 18,841 和 2,704。由於更大的視角變化引入了更多的噪聲，PKU-II 更具挑戰性，訓練集有 5,332 個樣本，測試集有 1,613 個樣本。

### 4.2. 實驗設置

**網路架構**:  
在我們的 MAMP 框架中，我們採用了一個基本的視覺 Transformer [12] 作為骨幹網路，由 $L_e = 8$ 個相同的構建模塊組成。在每個模塊中，嵌入維度設為 256，多頭自注意力模塊的頭數為 8，前饋網路的隱藏層維度為 1024。我們對嵌入的輸入施加可學習的時空位置嵌入。在預訓練期間使用的 Transformer 解碼器設置與骨幹編碼器一致，不過解碼層 $L_d$ 的數量減少到 5。

**數據處理細節**:  
給定一條原始骨架序列，首先從中隨機裁剪出一個比例為 $p$ 的連續片段（$p$ 在訓練期間從 [0.5, 1] 之間隨機選取，測試時固定為 0.9）。然後，裁剪出的片段通過雙線性插值被調整到固定長度 $T_s$，$T_s$ 默認設置為 120。

**預訓練細節**:  
在預訓練期間，輸入標記的遮蔽率設置為 90%。目標運動序列 $M^{target}$ 的步幅設為  $m = 1$，並使用零填充。我們使用 AdamW [33] 優化器，權重衰減為 0.05，beta 參數設為 (0.9, 0.95)。我們將網路預訓練 400 個 epoch，批次大小為 128。學習率在前 20 個暖身 epoch 內從 0 線性增加到 1e-3，隨後通過餘弦衰減調整到 5e-4。實驗在四個 NVIDIA RTX 3090 GPU 上使用 PyTorch 框架進行。

### 4.3. 與最新方法的比較

**線性評估結果**:  
在線性評估協議中，預訓練的骨幹網路被固定，並使用監督學習訓練後附的線性分類器 100 個 epoch，批次大小為 256，學習率為 0.1，隨後通過餘弦衰減將學習率逐步調整為 0。表 1 展示了在 NTU-60、NTU-120 和 PKU-MMD 數據集上的結果。我們包括了最新的高性能方法進行比較，例如 GL-Transformer [20]、CPM [59]、CMD [34]、3s-CrosSLR [23] 和 3s-AimCLR [49]。正如我們所看到的，僅使用關節流作為輸入，我們提出的 MAMP 在所有數據集上都優於這些方法。具體而言，MAMP 在具有挑戰性的 NTU-60 x-sub 和 NTU-120 x-sub 中分別比先前的最先進方法 CMD 提高了 5.5% 和 8.3%。為了公平比較，我們還在相同設置下重新實現了 Skeleton-MAE [53]（稱為 SkeletonMAE*），並取得了改進的性能。我們發現 MAMP 在三個數據集的六個子集中均顯著優於 SkeletonMAE*，顯示了與自我重建關節相比，遮蔽運動預測的優越性。

![[PaperWithCode/17-MAMP/Table1.png]]
表 1. 線性評估協議下 NTU-60、NTU-120 和 PKU-MMD 資料集的效能比較。 * 表示在我們的框架下重新實現的版本，其中實現了改進的性能。

**微調評估結果**:  
在微調評估協議中，將 MLP 頭附加到預訓練的骨幹網路上，並對整個網路進行 100 個 epoch 的完全微調，批次大小為 48。學習率在前 5 個暖身 epoch 內從 0 線性增加到 3e-4，隨後通過餘弦衰減調整到 1e-5。我們還採用了逐層學習率衰減 [10]，如 [2] 所述。表 2 和表 3 展示了在 NTU-60 和 NTU-120 上的微調性能。由於 transformer 具有較弱的歸納偏置，在直接從頭開始訓練時並未展示出令人滿意的性能，這符合預期，因為 transformer 需要大量的訓練數據來有效防止過擬合。經過我們提出的 MAMP 框架的預訓練後，網路在 NTU-60 和 NTU-120 數據集的四個子集上展示了顯著的性能提升，範圍從 5% 到 13% 不等。最終結果超過了所有先前的方法，甚至超過了使用多流合成的方法，如 Colorization [58]、MCC [47] 和 ViA [56]。此外，我們的 MAMP 也在很大程度上優於重新實現的 SkeletonMAE*。

我們還將 MAMP 與一些頂尖的監督學習方法進行了比較，如 PoseC3D [15]、CTR-GCN [5] 和 InfoGCN [8] 如表 4。結果表明，在不進行合成的情況下，MAMP 優於大多數頂尖方法，特別是在較大的 NTU-120 數據集上。

![[PaperWithCode/17-MAMP/Table2.png]]
表 2. 在微調評估協議下 NTU-60 資料集的效能比較。

![[PaperWithCode/17-MAMP/Table3.png]]
表 3. 在微調評估協議下 NTU-120 資料集的效能比較。

![[PaperWithCode/17-MAMP/Table4.png]]
表 4. 在 NTU-60 和 NTU-120 資料集上與完全監督方法的效能比較。請注意，我們的 MAMP 在評估期間不會執行多流整合。

**半監督評估結果**:  
按照之前的工作 [23, 34, 48]，在半監督評估協議中，我們一起微調後附的分類層和預訓練的編碼器，但僅使用一小部分訓練集。除了這一點之外，我們保持其他訓練設置與微調評估協議一致。根據 [23, 49, 59]，我們報告了在使用 1% 和 10% 訓練集進行 NTU-60 數據集的性能。考慮到在訓練數據選擇過程中的隨機性，我們報告了五次運行的平均結果作為最終結果。表 5 顯示，我們提出的 MAMP 顯著優於先前的工作，如 3s-AimCLR [49]、CPM [59]、CMD [34] 和 SkeletonMAE* [53]。當僅使用 1% 的訓練數據時，MAMP 在 X-sub 和 X-view 中分別比 SkeletonMAE* 提高了 11.6% 和 14.0%。與從頭開始訓練相比，MAMP 預訓練在 NTU-60 的所有子集上帶來了超過 15.5% 的性能提升。

![[PaperWithCode/17-MAMP/Table5.png]]
表 5. 半監督評估協議下 NTU-60 資料集的效能比較。我們將五次運行的平均值報告為最終性能。

**遷移學習評估結果**:  
在遷移學習評估協議中，網路首先在源數據集上進行預訓練，然後在不同的目標數據集上進行微調。通過這種方式，檢驗了學習到的表示的泛化能力。在本文中，目標數據集是 PKU-MMD II，而源數據集分別是 NTU-60、NTU-120 和 PKU-MMD I。表 6 的結果顯示，與以前的方法相比，我們提出的 MAMP 框架學習的表示展現了最佳的遷移性，分別在三個源數據集中比重新實現的 SkeletonMAE* 提高了 12.2%、12.2% 和 7.6%。

![[PaperWithCode/17-MAMP/Table6.png]]
表 6. 遷移學習評估協定下 PKU-II 資料集的效能比較。來源資料集是 NTU-60、NTU-120 和 PKU-I 資料集。
### 4.4. 消融研究

**Masked Motion Prediction 的優越性**:  
如表 7 所示，為了驗證 Masked Motion Prediction 的優越性，我們設計了四個不同的消融實驗。對於原始數據的關節和運動流，遍歷了所有可能的模型輸入和重建目標。我們發現，從關節到運動的預測明顯優於其他策略。在線性評估協議下，我們的 MAMP 分別在 NTU-60 和 NTU-120 上超過了關節到關節的預測（採用於 [53]）10.1% 和 6.1%。這表明，在預訓練期間，從靜態骨架預測動態運動有助於更好地對 3D 人類動作進行上下文建模。

我們還在圖 3 中可視化了預訓練損失。與 SkeletonMAE 的快速收斂不同，masked motion prediction 作為預訓練目標更加困難。

![[PaperWithCode/17-MAMP/Table7.png]]
表7.掩蔽運動預測優越性的消融研究。性能是根據線性評估協議在 NTU-60 X-sub 和 NTU-120 X-sub 資料集上進行評估的。

**遮蔽採樣策略**:  
在我們的方法中，我們採用了 vanilla transformer 作為骨幹網路，其中可以自由遮蔽任意時空位置的嵌入特徵，與 MAE [17] 類似。為了驗證所提出的 motion-aware 遮蔽策略的有效性，我們將其性能與隨機遮蔽進行了比較，結果如表 8 所示。我們的 motion-aware 遮蔽策略在 NTU-60 和 NTU-120 上分別帶來了 1.2% 和 1.3% 的絕對性能提升。這表明，運動信息作為經驗性的語義豐富先驗，可以有效地引導骨架的遮蔽過程。

![[PaperWithCode/17-MAMP/Table8.png]]
表 8. 掩模採樣策略的消融研究。性能是根據線性評估協議在 NTU-60 X-sub 和 NTU-120 X-sub 資料集上進行評估的。

**段長**:  
我們評估了在關節嵌入過程中使用的不同段長 l 下學習到的表現。為了公平比較，我們將原始輸入序列調整為固定長度$Te = Ts/l = 30$。如表 9 所示，段長為 4 時在 NTU-60 和 NTU-120 數據集上帶來了最佳性能。

![[PaperWithCode/17-MAMP/Table9.png]]
表 9. 聯合嵌入過程中所使用的段長 l 的消融研究。為了公平比較，調整輸入長度Ts以確保嵌入的特徵具有固定長度Te。性能是根據線性評估協議在 NTU-60 X-sub 和 NTU120 X-sub 資料集上進行評估的。

**解碼器設計**:  
我們實驗了不同層數和寬度（特徵維度）的 transformer 解碼器。如表 10 (a) 所示，當解碼層數為 3 和 5 時，MAMP 分別在 NTU-60 和 NTU-120 數據集上表現最好。解碼器寬度的實驗結果見表 10 (b)，其中寬度為 256 帶來了最佳性能。總體而言，在 MAMP 框架中，我們默認採用 5 層、寬度為 256 的解碼器。

![[PaperWithCode/17-MAMP/Table10.png]]
表 10. 解碼器設計的消融研究。性能是根據線性評估協議在 NTU-60 X-sub 和 NTU-120 X-sub 資料集上進行評估的。

**遮蔽比例**:  
如圖 4 所示，我們對不同的遮蔽比例進行了實驗。NTU-60 X-sub 的結果顯示，過大或過小的遮蔽比例都會對性能產生負面影響。我們經驗性地發現，遮蔽比例為 90% 時表現最佳。

**預訓練進度表**:  
我們研究了預訓練進度表長度的影響。如圖 5 所示，SkeletonMAE 和我們的 MAMP 都隨著預訓練進度的延長而表現出更高的性能。值得一提的是，在 80 到 400 個 epoch 內，我們的 MAMP 對所有預訓練進度表長度的表現均顯著優於 SkeletonMAE，證明了所提出的 masked motion prediction 策略的穩定性和優越性。

![[Figure3-4-5.png]]
圖 3. 訓練前損失圖。與 SkeletonMAE 中關節的屏蔽自重建相比，屏蔽運動預測是更困難的預訓練目標。
圖 4. 掩蔽比的消融研究。性能是根據線性評估協議在 NTU-60 X-sub 數據集上進行評估的。
圖 5. SkeletonMAE 和我們的 MAMP 的預訓練時間表。性能是根據線性評估協議在 NTU-60 X-sub 數據集上進行評估的。

## 5. 結論

在本研究中，我們提出了 MAMP，一個簡單但有效的 3D 動作表徵學習框架。我們展示了，與傳統的人體關節遮蔽自重建相比，遮蔽關節到運動的預測在 3D 動作的上下文運動建模方面更為有效。考慮到骨架序列的高時間冗餘性，我們進一步設計了 motion-aware 遮蔽策略，將運動強度作為經驗性語義豐富先驗，以適應性地遮蔽骨架，促進對語義豐富的時間區域的更好關注。我們在三個主流基準數據集上進行了廣泛的實驗，並採用了四種評估協議。結果表明，所提出的 MAMP 帶來了顯著的性能提升，並創造了一系列新的最先進紀錄，充分釋放了 vanilla transformer 在 3D 動作建模中的巨大潛力。