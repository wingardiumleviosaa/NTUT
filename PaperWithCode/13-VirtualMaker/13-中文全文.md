#資料集/H36M #資料集/3DPW #資料集/SURREAL #骨架偵測/3D熱圖/HRNet-W48 #骨架偵測/骨架資料處理/Active-set #骨架偵測/3D熱圖/volumetric-CNN #骨架偵測/骨架資料處理/線性乘法插值 #運行框架/GraphCMR，SPIN，Pose2Mesh，HybrIK，CLIFF 
## 摘要  
受體積式3D姿勢估計成功的啟發，最近一些人體網格估計器提出將3D骨架作為中間表示，從中利用網格拓撲來回歸密集的3D網格。然而，提取骨架時會丟失身體形狀信息，導致性能表現一般。先進的動作捕捉系統通過在身體表面放置密集的物理標記解決了這一問題，從非剛性運動中提取逼真的網格。然而，這些系統無法應用於沒有標記的野外圖像。在這項工作中，我們提出了一種名為虛擬標記的中間表示，該表示基於大規模動作捕捉數據，以生成式方式學習身體表面上的64個標誌性關鍵點，模擬物理標記的效果。虛擬標記可以從野外圖像中精確檢測，並通過簡單的插值重建具有逼真形狀的完整網格。我們的方法在三個數據集上優於最先進的方法。特別是在具有多樣化身體形狀的 SURREAL 數據集上，顯著超越了現有方法。代碼可在 [https://github.com/ShirleyMaxx/VirtualMarker](https://github.com/ShirleyMaxx/VirtualMarker) 獲得。


## 1. 引言  
3D 人體網格估計的目標是估計位於人體表面的網格頂點的3D位置。由於這一任務可以應用於許多領域，如虛擬現實 [15]，因此引起了計算機視覺和計算機圖形學社區的大量關注 [3, 10, 19, 25, 27, 30, 35, 37, 43, 51]。最近，基於深度學習的方法 [7, 19, 29] 在基準數據集上的精度有了顯著提高。

早期的方法 [19, 51] 提出直接從圖像回歸網格模型（如 SMPL [36]）的姿態和形狀參數。儘管這種方法簡單明了，但其精度通常低於最新的技術。首先，從圖像特徵到模型參數的映射是高度非線性的，並且受到圖像和模型錯位的影響 [29]。此外，由於捕捉過程的複雜性，現有的網格數據集 [16, 28, 38, 54] 規模較小，且僅限於簡單的實驗室環境。訓練數據的不足嚴重限制了這些方法的性能。

近來，受體積式姿勢估計成功的啟發 [44, 45, 47, 50, 59, 65]，一些工作 [26, 39] 開始將網格估計表述為密集的 3D 關鍵點檢測任務。例如，在 [26, 39] 中，作者提出回歸所有頂點的 3D 位置。然而，由於頂點數量達到數千，這種方法的計算成本很高。Moon 和 Lee [39] 通過將 3D 熱圖分解為多個 1D 熱圖來提高效率，但以較低的精度為代價。Choi 等人 [7] 提出首先在圖像中檢測較稀疏的骨架關節，然後利用網格拓撲回歸密集的 3D 網格。這一方向的方法吸引了越來越多的關注 [7, 29, 55]，有兩個原因。首先，3D 骨架估計作為代理任務可以利用大量的 2D 姿勢數據集，從而顯著提高精度。其次，從骨架回歸網格效率較高。然而，在提取 3D 骨架時，人體形狀的重要信息被忽略了，這一點過去很少被注意到。因此，像瘦弱或肥胖等不同體型無法準確估計（見圖 1）。

![[PaperWithCode/13-VirtualMaker/Figure1.png]]
圖 1. 四個不同體型範例的網格估計結果。使用 3D 骨架作為中間表示的 Pose2Mesh [7] 無法預測準確的形狀。我們基於虛擬標記的方法獲得了準確的估計。

專業的基於標記的動作捕捉（mocap）方法 MoSh [35] 在身體表面放置物理標記，並通過其微小的非剛性運動來提取精確的網格形狀。然而，物理標記限制了該方法只能用於實驗室環境。我們受到啟發，思考是否可以在網格上識別出一組虛擬標記，如肘部和手腕，可以從野外圖像中檢測，並允許恢復準確的體型？理想的虛擬標記應滿足幾個要求。首先，標記的數量應該遠少於網格頂點數，這樣我們可以使用體積表示高效地估計其 3D 位置。其次，標記應能捕捉網格拓撲，以便可以從中準確回歸完整的網格。第三，虛擬標記應具有明顯的視覺特徵，以便可以從圖像中檢測出來。

在這項工作中，我們提出了一種基於原型分析 [12] 的學習算法，旨在識別一部分網格頂點作為虛擬標記，這些標記盡可能滿足上述要求。圖 2 顯示，學習到的虛擬標記粗略勾勒出身體形狀和姿勢，為估計具有準確形狀的網格鋪平了道路。然後，我們提出了一個簡單的 3D 網格估計框架，如圖 3 所示。首先，它基於 [47] 學習 3D 關鍵點估計網絡來檢測虛擬標記的 3D 位置。接著，我們僅通過插值來恢復完整的網格。插值權重在表示學習步驟中預先訓練，並根據每張圖像的虛擬標記的預測置信度由一個輕量級網絡進行調整。

我們在三個基準數據集上對我們的方法進行了廣泛的評估，並且在所有數據集上均優於最先進的方法。特別是，在具有多樣體型的 SURREAL 數據集 [53] 上，我們的方法取得了顯著的增益。我們的消融研究也驗證了虛擬標記表示在恢復準確形狀方面的優勢。最後，該方法展現了良好的泛化能力，並能生成視覺上吸引人的野外圖像結果。

![[PaperWithCode/13-VirtualMaker/Figure2.png]]
圖 2. 左：後視圖和前視圖中學習的虛擬標記（藍色球）。灰色的球意味著它們在前視圖中是不可見的。虛擬標記的作用與實體身體標記類似，並且大致勾勒出身體形狀。右：我們的方法的網格估計結果，從左到右分別是輸入影像、覆蓋在影像上的估計3D 網格以及三個不同的視點，分別顯示估計的3D 網格和我們的中間預測虛擬標記（藍色球）。

## 2. 相關工作

### 2.1 基於優化的網格估計  
在深度學習主導該領域之前，3D 人體網格估計 [2, 28, 35, 41, 60] 主要基於優化，即通過優化人體網格模型的參數來匹配觀測結果。例如，Loper 等人 [35] 提出了 MoSh 方法，通過優化 SMPL 參數，使網格與 3D 標記點的位置對齊。由於其高精度，通常用於獲取基準數據集的真實 3D 網格。隨後的工作提出基於 2D 圖像線索來優化模型參數或網格頂點 [2, 11, 28, 41, 60]。它們從圖像中提取中間表示，如 2D 骨架，並通過最小化模型投影與中間表示（如 2D 骨架）之間的差異來優化網格模型。這些方法通常對初始化敏感，並且容易陷入局部最優解。

### 2.2 基於學習的網格估計  
最近，大多數工作遵循基於學習的框架，並取得了有前途的結果。深度網絡 [19, 25, 27, 37, 51] 用於從圖像特徵中回歸 SMPL 參數。然而，從圖像空間到參數空間的映射是高度非線性的 [39]。此外，這些方法還面臨網格與圖像像素錯位的問題 [62]。這些問題使得學習一個準確且具有通用性的模型變得困難。

一些工作提出先引入代理任務來獲取中間表示，希望能緩解學習的難度。具體而言，已提出的中間表示包括物理標記 [61]、IUV 圖像 [57, 62–64]、身體部位分割掩碼 [24, 28, 40, 52] 和身體骨架 [7, 29, 49, 55]。特別是，THUNDR [61] 首先從圖像中估計物理標記的 3D 位置，然後從這些 3D 標記重建網格。物理標記可以看作是身體形狀和姿態的簡化表示。儘管它非常準確，但無法應用於沒有標記的野外圖像。相比之下，人體骨架是一種流行的人體表示方式，可以在野外圖像中穩定檢測到。Choi 等人 [7] 提出先估計 3D 骨架，然後從中估計完整的網格。然而，由於 3D 骨架的過度簡化，準確恢復體型非常困難。

我們的工作屬於基於學習的範疇，並與使用物理標記或骨架作為中間表示的工作相關。但與它們不同的是，我們提出了一種新的中間表示，名為虛擬標記，它比身體骨架更具表現力，能減少姿勢和形狀估計中的模糊性，並且可以應用於野外圖像。


## 3. 方法

在本節中，我們詳細描述我們的方法。首先，3.1 節介紹我們如何從動作捕捉數據中學習虛擬標記表示。然後在 3.2 節中，我們展示了從圖像中進行網格估計的整體框架。最後，3.3 節討論損失函數和訓練細節。

### **3.1 虛擬標記表示**  
我們將網格表示為一個頂點位置向量 $\mathbf{x}\in\mathbb{R}^{3M}$，其中 M 是網格頂點的數量。將一個動作捕捉數據集（例如 [16]）中包含 N 個網格的數據表示為 $\widehat{\mathbf{X}}=[\mathbf{x}_1, ...,\mathbf{x}_N] \in \mathbb{R}^{3M\times N}$。為了揭示頂點之間的潛在結構，我們將其重塑為 $\mathbf{X}\in\mathbb{R}^{3N\times M}$，其中每一列 $\mathbf{x}_i\in\mathbb{R}^{3N}$ 代表數據集中第 $i^{th}$ 個頂點的所有可能位置 [16]。

$X$ 的 rank 小於 $M$，因為網格表示是平滑且冗餘的，一些頂點可以由其他頂點準確重建。儘管將 PCA [18] 應用於 $X$ 以計算特徵向量作為虛擬標記來重建其他頂點似乎是自然的做法，但這無法保證虛擬標記對應於網格頂點，從而使其難以從圖像中檢測出來。相反，我們旨在學習 $K$ 個虛擬標記 $\mathbf{Z}=\begin{bmatrix}\mathbf{z}_1,...,\mathbf{z}_K\end{bmatrix}\in\mathbb{R}^{3N\times K}$，並儘可能滿足以下兩個要求。首先，它們可以通過線性組合準確重建完整網格 $X$：$X = ZA$，其中 $\mathbf{A}\in\mathbb{R}^{K\times{M}}$ 是編碼虛擬標記與網格頂點之間空間關係的係數矩陣。其次，它們應該在圖像中具有明顯的視覺模式，以便可以輕鬆地從圖像中檢測出來。理想情況下，它們應該位於網格的表面。

我們通過最小化重建誤差並添加兩個額外的約束，使用原型分析 [4, 12] 來學習 $Z$：（1）每個頂點 xᵢ 可以通過 $Z$ 的凸組合進行重建；（2）每個標記 $z_i$ 應該是網格頂點 $X$ 的凸組合：

$$\min_{{\begin{array}{l}\boldsymbol{\alpha}_{i}\boldsymbol{\in}\Delta_{K}for1\boldsymbol{\leq}i\boldsymbol{\leq}M,\\\boldsymbol{\beta}_{j}\boldsymbol{\in}\Delta_{M}for1\boldsymbol{\leq}j\boldsymbol{\leq}K\end{array}}}||\mathbf{X-XBA}||_{F}^{2}, \tag{1}$$

其中 $\textbf{A = }[\boldsymbol{\alpha}_1,...,\boldsymbol{\alpha}_M] \in \mathbb{R}^{K\times M}$，每個 $α$ 屬於單純形 $\Delta_K\triangleq\{\boldsymbol{\alpha}\in\mathbb{R}^K\text{ s.t.}\boldsymbol{\alpha}\succeq0\text{ and}\left|\left|\boldsymbol{\alpha}\right|\right|_1=1\}$，$\mathbf{B} = [\boldsymbol{\beta}_1,...,\boldsymbol{\beta}_K] \in \mathbb{R}^{M\times K}, \boldsymbol{\beta}_j \in \Delta_M.$。我們採用 Active-set 算法 [4] 來解決目標 (1)，並獲得學習到的虛擬標記 $\mathbf{Z}=\mathbf{X}\mathbf{B}\in\mathbb{R}^{3N\times K}$。正如 [4, 12] 所示，這兩個約束鼓勵虛擬標記 $Z$ 揭示頂點之間的潛在結構，因此它們學會靠近網格的極端點並盡可能位於身體表面。

**後處理**  
由於人體是左右對稱的，我們調整 $Z$ 以反映這一特性。我們首先將每個 $z_i ∈ Z$ 替換為網格上最接近的頂點，並獲得 $\widetilde{\mathbf{Z}}\in\mathbb{R}^{3\times K}$。這一步允許我們計算每個標記的左或右對應物。然後，我們將右側身體的標記替換為左側身體的對稱頂點，並獲得對稱標記 $\widetilde{\mathbf{Z}}^{sym}\in\mathbb{R}^{3\times K}$。最後，我們通過最小化 $||\mathbf{X}-\mathbf{X}\widetilde{\mathbf{B}}^sym\widetilde{\mathbf{A}}^{sym}||_F^2$ 並使 $\widetilde{\mathbf{Z}}^{sym}=\mathbf{X}\widetilde{\mathbf{B}}^{sym}$，更新 $B$ 和 $A$。更多細節在附加資料中詳細說明。

圖 2 顯示了在動作捕捉數據集 [16] 上學習到的虛擬標記，並進行了後處理。這些標記類似於物理標記，並大致勾勒出人體形狀，這符合我們的預期。它們大致均勻地分佈在身體表面，有些標記位於接近人體關鍵點的地方，這些點具有明顯的視覺特徵，可以準確檢測。表 1 顯示了使用原始標記 $XB$ 和對稱標記 $\mathbf{X}\widetilde{\mathbf{B}}^{sym}$ 的重建誤差。兩者均能準確重建網格。

![[PaperWithCode/13-VirtualMaker/Table1.png]]
表 1. 分別使用 H3.6M 資料集 [16] 上的原始標記集和對稱標記集的重建誤差。誤差很小，表明它們具有足夠的表達能力並且可以準確地重建所有頂點。

### 3.2. 網格估計框架  
基於虛擬標記，我們提出了一個簡單但有效的框架，用於從單張圖像端到端進行 3D 人體網格估計。如圖 3 所示，該框架由兩個分支組成。第一個分支使用體積 CNN [47] 估計標記的 3D 位置 $\hat{P}$，第二個分支通過預測係數矩陣 $\hat{A}$ 來重建完整的網格 $\hat{M}$：  

$$\hat{M} = \hat{P} \hat{A} \tag{2}$$  
我們將更詳細地描述這兩個分支。

![[PaperWithCode/13-VirtualMaker/Figure3.png]]
圖 3.我們的框架概述。給定輸入影像 $I$，它首先估計虛擬標記的 3D 位置 $\hat{P}$。然後我們根據虛擬標記的估計置信度得分 $C$ 更新係數矩陣 $\hat{A}$。最後，完整的人體網格可以透過tj $\hat{M} = \hat{P} \hat{A}$ 簡單地恢復。

**3D 標記估計**  
我們訓練一個神經網絡，從圖像中估計 3D 熱圖 $\hat{\mathbf{H}}=[\hat{\mathbf{H}}_1, ..., \hat{\mathbf{H}}_K]\in\mathbb{R}^{K\times D\times H\times W}$。熱圖對每個標記的每個體素編碼了對應的可能性。3D 空間被離散化為 $D × H × W$ 個體素。每個標記的 3D 位置 $\hat{\mathbf{P}}_z\in\mathbb{R}^3$ 通過對應熱圖 $\hat{\mathbf{H}}_z$ 的質心計算得出 [47]，具體如下：  
\
$$\hat{\mathbf{P}}_z=\sum_{d=1}^D\sum_{h=1}^H\sum_{w=1}^W(d,h,w)\cdot\hat{\mathbf{H}}_z(d,h,w). \tag{3}$$

所有標記的位置表示為 $\hat{\mathbf{P}}=[\hat{\mathbf{P}}_1,\hat{\mathbf{P}}_2,\cdots,\hat{\mathbf{P}}_K]$。

**插值**  
理想情況下，如果我們對所有虛擬標記 $\hat{\mathbf{P}}$ 進行了準確的估計，那麼我們可以通過將 $\hat{\mathbf{P}}$  與固定的係數矩陣 $\widetilde{\mathbf{A}}^{sym}$ 相乘來恢復完整的網格，這在表 1 中已被驗證具有足夠的準確性。然而，在實踐中，某些標記可能因在單目設置中被遮擋而出現較大的估計誤差。這種情況經常發生，例如，當一個人面向攝像機時，背後的標記會被遮擋。因此，如果直接將這些不準確的標記位置與固定矩陣 $\widetilde{\mathbf{A}}^{sym}$ 相乘，會給最終的網格帶來較大的誤差。

我們的解決方案是更多依賴那些準確檢測到的標記。為此，我們提出根據標記的估計置信度更新係數矩陣。在實踐中，我們只需在每個標記的估計位置上取熱圖得分，即 Hˆ z(Pˆ z)，並將它們輸入到一個全連接層中，以獲取係數矩陣 $\hat{A}$。然後通過 $\hat{M} = \hat{P} \hat{A}$ 重建網格。


### 3.3. 訓練  
我們以監督方式端到端訓練整個網絡。整體損失函數定義為：

$$\mathcal{L}=\lambda_{vm}\mathcal{L}_{vm}+\lambda_c\mathcal{L}_{conf}+\lambda_m\mathcal{L}_{mesh}. \tag{4}$$

**虛擬標記損失**  
我們將虛擬標記損失 $\mathcal{L}_{vm}$ 定義為預測的 3D 虛擬標記 $\hat{P}$ 和真實標記之 $\hat{P^*}$ 間的 $L_1$ 距離，如下所示：

$$\mathcal{L}_{vm}=\|\hat{\mathbf{P}}-\hat{\mathbf{P}}^*\|_1. \tag{5}$$

請注意，根據 3.1 節所述，我們可以從真實網格中輕鬆獲得真實標記 $\hat{P^*}$，而無需額外的人工標註。

**置信度損失**  
我們還要求 3D 熱圖具有合理的形狀，因此，包含真實標記位置 $\hat{P}^*_z$ 的體素上的熱圖得分應具有最大值，這與之前的工作 [17] 一致：

$$\mathcal{L}_{conf}=-\sum_{z=1}^Klog(\hat{\mathbf{H}}_z(\hat{\mathbf{P}}_z^*)). \tag{6}$$

**網格損失**  
根據 [39]，我們將網格損失 $\mathcal{L}_{mesh}$ 定義為四種損失的加權總和：

$$\mathcal{L}_{mesh}=\mathcal{L}_{vertex}+\mathcal{L}_{pose}+\mathcal{L}_{normal}+\lambda_e\mathcal{L}_{edge}. \tag{7}$$

– **頂點坐標損失**  
我們採用預測的 3D 網格坐標 $\hat{M}$ 與真實網格 $\hat{M}^*$ 之間的 $L1$ 損失，如下所示：

$$\mathcal{L}_{vertex}=\|\hat{\mathbf{M}}-\hat{\mathbf{M}}^*\|_1. \tag{8}$$

– **姿勢損失**  
我們使用從網格 $\hat{\mathbf{M}}\mathcal{J}$ 回歸的 3D 關鍵關節與真實關節  $\hat{\mathbf{J}}^*$ 之間的 $L1$ 損失，如下所示：

$$\mathcal{L}_{pose}=\|\hat{\mathbf{M}}\mathcal{J}-\hat{\mathbf{J}}^*\|_1, \tag{9}$$

其中 $\mathcal{J}\in\mathbb{R}^{M\times J}$ 是 SMPL 模型中的預定義關節回歸矩陣 [2]。

– **表面損失**  
為了提高表面的平滑度 [56]，我們使用 $\mathcal{L}_{normal}$ 來監控三角形面的法向量與真實法向量的誤差，並使用 $\mathcal{L}_{edge}$ 來監控預測網格的邊長與真實邊長的誤差：

$$\begin{aligned}&\mathcal{L}_{normal}=\sum_f\sum_{\{i,j\}\subset f}\left|\left\langle\frac{\hat{\mathbf{M}}_i-\hat{\mathbf{M}}_j}{\|\hat{\mathbf{M}}_i-\hat{\mathbf{M}}_j\|_2},\hat{\mathbf{n}}_f^*\right\rangle\right|,\\&\mathcal{L}_{edge}=\sum_f\sum_{\{i,j\}\subset f}\left|\|\hat{\mathbf{M}}_i-\hat{\mathbf{M}}_j\|_2-\|\hat{\mathbf{M}}_i^*-\hat{\mathbf{M}}_j^*\|_2\right|.\end{aligned} \tag{10}$$\

其中 $f$ 和 $\hat{n}^*_f$ 分別表示網格中的三角面及其對應的真實單位法向量，$\hat{M}_i$ 表示 $\hat{M}$ 的第 $i^{th}$ 個頂點，$*$ 表示真實標註。


## 4. 實驗  

### **4.1. 數據集和評估指標**

**H3.6M [16]**  
我們使用 (S1, S5, S6, S7, S8) 進行訓練，使用 (S9, S11) 進行測試。如 [7, 19, 32, 33] 中所述，我們報告從估計網格中推導出的姿勢的 MPJPE（平均關節位置誤差）和 PA-MPJPE（基於姿勢對齊的平均關節位置誤差）。我們還報告整個網格的每頂點平均誤差（MPVE）。  

**3DPW [54]**  
該數據集是在自然場景中收集的。按照之前的工作 [24, 32, 33, 61]，我們使用 3DPW 的訓練集來學習模型，並在測試集上進行評估。使用的評估指標與 H3.6M 相同。  

**SURREAL [53]**  
這是一個大規模的合成數據集，具有 GT SMPL 註釋，並且樣本在體型、背景等方面具有多樣性。我們使用其訓練集進行模型訓練，並按照 [7] 在測試集上進行評估。

### **4.2. 實現細節**  
我們在 H3.6M [16] 訓練集上學習了 64 個虛擬標記。我們對所有數據集使用相同的標記集，而不是在每個數據集上分別學習一組標記。如 [7, 19, 23, 26, 32, 33, 39, 61] 所述，我們使用 MPI-INF-3DHP [38]、UP-3D [28] 和 COCO [34] 的訓練集進行混合訓練，並在 H3.6M 和 3DPW 數據集上進行實驗。我們使用 HRNet-W48 [46] 作為圖像特徵主幹來估計 3D 虛擬標記，並適應 3D 姿勢估計器 [47]。每個維度上的體素數量設置為 64，即 $D = H = W = 64$，用於生成 3D 熱圖。如 [19, 26, 39] 所述，我們從輸入圖像中裁剪出每個人的區域，並將其大小調整為 256 × 256。我們使用 Adam [22] 優化器訓練整個框架，訓練 40 個 epoch，批量大小為 32。兩個分支的學習率分別設置為 $5 × 10^{-4}$ 和 $1 × 10^{-3}$，並在第 30 個 epoch 後減半。更多細節請參見附錄。

### **4.3. 與最新技術的比較**

**H3.6M 數據集的結果**  
表 2 將我們的方法與 H3.6M 數據集上的最新技術進行了比較。我們的方法在性能上具有競爭力，甚至優於某些方法。特別是，我們的方法超越了使用骨架（如 Pose2Mesh [7] 和 DSD-SATN [49]）、身體標記（如 THUNDR [61]）或 IUV 圖像 [62, 64] 作為代理表示的方法，這證明了虛擬標記表示的有效性。

**3DPW 數據集的結果**  
我們的方法在 3DPW 數據集上的表現同樣與最新技術進行了比較（見表 2）。我們的方法在所有方法中取得了最先進的結果，證實了虛擬標記表示相對於骨架表示（如 Pose2Mesh [7] 和 DSD-SATN [49]）及其他代理表示（如 PyMAF [64] 中使用的 IUV 圖像）的優勢。特別是，我們的方法顯著超越了 I2L-MeshNet [39]、METRO [32] 和 Mesh Graphormer [33]，這表明虛擬標記比直接檢測所有頂點更合適和有效，因為大多數頂點並沒有足夠的區別性，無法準確檢測。

**SURREAL 數據集的結果**  
該數據集在體型方面有更多樣化的樣本。結果如表 3 所示，我們的方法在各方面都超越了最先進的方法，尤其是在 MPVE 指標上。圖 1 顯示了一些具有挑戰性的情況，沒有經過特意篩選。骨架表示丟失了體型信息，因此方法 [7] 只能恢復平均形狀。相比之下，我們的方法能夠產生更加準確的網格估計結果。

![[PaperWithCode/13-VirtualMaker/Table2.png]]
表 2. H3.6M [16] 和 3DPW [54] 資料集上最新技術的比較。 † 表示使用時間線索。這些方法不具有嚴格的可比性，因為它們可能具有不同的主幹和訓練資料集。我們提供這些數字只是為了顯示概念驗證結果。

![[PaperWithCode/13-VirtualMaker/Table3.png]]
表 3. 與 SURREAL [53] 資料集上最新技術的比較。 * 表示在 2D 監督下對測試分割進行訓練。 「斯凱爾。 + 段。意味著同時使用骨架和分割。

### **4.4. 消融研究**

**虛擬標記表示**  
我們在表 4 中將我們的方法與兩個基線進行了比較。首先，在基線 (a) 中，我們用骨架表示替換了我們方法中的虛擬標記，其他部分保持與我們的方法 (c) 相同。我們的方法相比基線 (a) 取得了更低的 MPVE，這表明虛擬標記有助於比骨架更準確地估計體型。在基線 (b) 中，我們隨機從 6890 個網格頂點中選取 64 個作為虛擬標記。我們重複了五次實驗並報告了平均結果。可以看到，結果比我們的方法差，這是因為隨機選取的頂點可能無法表現出重建其他頂點所需的能力，或由於缺乏顯著的視覺模式，無法從圖像中準確檢測到。這些結果驗證了我們學習策略的有效性。

![[PaperWithCode/13-VirtualMaker/Table4.png]]
表 4. 我們在 H3.6M 和 SURREAL 資料集上的方法的虛擬標記表示的消融研究。 「骨架」意味著使用稀疏地標聯合表示。 「隨機虛擬標記」是指從所有頂點中隨機選擇虛擬標記，無需學習。 (c) 是我們的方法，其中使用了學習到的虛擬標記。

圖 1 展示了 SURREAL 測試集上一些定性結果。使用骨架表示（例如 Pose2Mesh [7]）的基線估計的網格體型不準確。這是合理的，因為骨架過於簡化，無法有效恢復體型，它隱式地為整個訓練數據集學習了一個平均體型。相反，使用虛擬標記估計的網格具有更好的質量，這是由於虛擬標記的強大表現能力，從而能夠優雅地處理不同的體型。圖 4 還展示了 H3.6M 測試集上的一些定性結果，為清晰起見，我們還在圖中繪製了中間表示（藍色小球）。

![[PaperWithCode/13-VirtualMaker/Figure4.png]]
圖 4. H3.6M 測試集上不同方法的網格估計結果。我們使用虛擬標記表示的方法比使用骨架表示的 Pose2Mesh 獲得了更好的形狀估計結果。注意身體的腰圍和手臂的粗細。

**虛擬標記的數量**  
我們評估了虛擬標記的數量如何影響 H3.6M [16] 數據集上的估計質量。圖 5 可視化了學習到的虛擬標記，這些標記都位於身體表面並靠近網格的極端點，這符合我們在 3.1 節中提到的預期。表 5（GT）顯示了當我們具有虛擬標記的真實 3D 位置時，網格重建的結果。當我們增加虛擬標記的數量時，網格重建誤差（MPVE）和回歸關鍵關節誤差（MPJPE）穩步下降。這是預期中的結果，因為使用更多虛擬標記提高了表示能力。然而，當我們需要從圖像中估計虛擬標記的位置時，使用更多虛擬標記並不能保證更小的估計誤差。這是因為新增的虛擬標記可能會帶來較大的估計誤差，從而影響網格估計結果。表 5（Det）中的結果顯示，當虛擬標記數量 $K$ 小於 96 時，增加 $K$ 會穩步減少 MPVE 誤差。然而，如果我們繼續增加 $K$，誤差會開始增大，這主要是因為新增的虛擬標記在圖像中難以檢測，從而對網格估計帶來了誤差。

![[PaperWithCode/13-VirtualMaker/Figure5.png]]
圖 5. 從左到右分別顯示不同數量 $K = 16、32、96$ 的學習虛擬標記的視覺化。

![[PaperWithCode/13-VirtualMaker/Table5.png]]
表 5. H3.6M [16] 資料集上不同數量的虛擬標記 ($K$) 的消融研究。 (GT) 當虛擬標記的 GT 3D 位置用於物鏡 (1) 時的網格重建結果。 （Det）當我們使用不同數量的虛擬標記 ($K$) 時，我們提出的框架所獲得的網格估計結果。

**係數矩陣**  
我們將我們的方法與使用固定係數矩陣 $\widetilde{\mathbf{A}}^{sym}$ 的基線進行了比較。圖 6 展示了質量比較結果。可以看到，使用固定係數矩陣 (a) 估計的網格大多具有正確的姿勢和形狀，但網格上也有一些瑕疵，而使用更新後的係數矩陣 (b) 可以得到更好的網格估計結果。如表 6 所示，使用固定係數矩陣的 MPVE 和 MPJPE 誤差比使用更新後的係數矩陣更大。這是由於當發生遮擋時，虛擬標記的估計誤差所導致的，這是無法避免的，因為背部的虛擬標記會被前面的身體自遮擋。因此，如果我們直接使用固定矩陣，不準確的標記位置會對最終的網格估計帶來較大的誤差。

![[PaperWithCode/13-VirtualMaker/Figure6.png]]
圖 6. 使用 (a) 固定係數矩陣  $\widetilde{\mathbf{A}}^{sym}$  和 (b) 更新的 $\hat{A}$ 時的網格估計值比較結果。請放大以更好地查看細節。

![[PaperWithCode/13-VirtualMaker/Table6.png]]
 表 6. 我們在 H3.6M 資料集上的方法的係數矩陣的消融研究。 「fixed」是指使用固定係數矩陣  $\widetilde{\mathbf{A}}^{sym}$  來重建網格。

### **4.5. 定性結果**  
圖 7（上）展示了我們的方法在 3DPW 測試集中自然圖像上估計的一些網格。最右側的案例顯示了一個典型的失敗情況，我們的方法因為嚴重遮擋，對左腿的姿勢估計錯誤。可以看到，這次失敗僅限於局部區域，身體的其餘部分仍然得到準確的估計。我們進一步分析了不準確的虛擬標記如何影響網格估計，即當人體部分被遮擋或截斷時的影響。根據我們模型最終學習的係數矩陣 $\hat{A}$，我們在圖 8 中突出顯示了虛擬標記與所有頂點之間的關係權重。我們可以看到，模型實際上學習了局部且稀疏的依賴關係，例如對於每個頂點，貢獻最大的虛擬標記都在其附近範圍內，如圖 8(b) 所示。因此，在推理過程中，如果一個虛擬標記因為遮擋或截斷而位置估計不準確，依賴於該標記的頂點可能會有不準確的估計，而其他頂點則幾乎不受影響。圖 2（右側）展示了更多遮擋或截斷發生的情況，我們的方法仍然能夠穩健地得到準確或合理的估計。值得注意的是，當發生截斷時，我們的方法仍然能夠推測出被截斷虛擬標記的位置。

圖 7（下）展示了我們在具有挑戰性的案例中估計的網格，這表明我們的模型在自然場景中的多樣姿態和動作上具有很強的泛化能力。更多質量結果請參見附錄。需要注意的是，由於數據集不提供頭部方向、面部表情、手或腳的監督，這些部分的估計結果不可避免地處於標準姿勢。除了這些以外，大多數錯誤是由於 3D 虛擬標記估計不準確引起的，這些問題可以通過更強大的估計器或更多樣化的訓練數據集在未來加以解決。

![[PaperWithCode/13-VirtualMaker/Figure7.png]]
圖 7. 頂部：透過我們的方法對 3DPW 測試集的圖像估計的網格。虛線框中最右邊的情況顯示了典型的故障。底部：透過我們的方法對具有挑戰性的情況（極端形狀或穿著長裙）的網路圖像估計的網格。

![[PaperWithCode/13-VirtualMaker/Figure8.png]]
圖 8. (a) 對於每個虛擬標記（由星號表示），我們根據平均係數矩陣 $\hat{A}$  突出顯示受影響最大的 30 個頂點（由彩色點表示）。 (b) 對於每個頂點（Dot），我們突出顯示貢獻最大的前 3 個虛擬標記（Star）。我們可以看到，依賴關係具有很強的局部性，當無法準確偵測到某些虛擬標記時，可以提高穩健性。

## **5. 結論**  
在本文中，我們提出了一種新的中間表示——虛擬標記，這比流行的骨架表示更具表現力，也比物理標記更易於使用。它能夠更準確且高效地重建 3D 網格，尤其是在處理多樣化體型時。此外，虛擬標記表示中的係數矩陣編碼了網格頂點之間的空間關係，使該方法能夠隱式地探索人體的結構先驗。該方法在網格估計結果上優於現有的最先進方法，並展示了儘管方法簡單卻具有優秀的泛化潛力。