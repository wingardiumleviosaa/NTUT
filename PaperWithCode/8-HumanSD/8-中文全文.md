 #資料集/HumanArt #資料集/LAION-Human  #資料集/GHI
#骨架偵測/tools/HumanArt #骨架偵測/HigherHRNet

![[PaperWithCode/8-HumanSD/Figure1.png]]
圖 1：本文重點介紹了具有精確姿態控制的多場景以人為中心的影像生成。每組顯示圖像包括：（a）由預先訓練的無姿勢文字引導穩定擴散（SD）生成[35]，（b）姿勢骨架圖像作為 ControlNet 和我們提出的 HumanSD 的條件，（c） ）由ControlNet [ 53] 生成，以及（d）由HumanSD（我們的）生成。 ControlNet 和 HumanSD 接收文字和姿勢條件。 HumanSD在（一）具有挑戰性的姿勢、（二）精確的繪畫風格、（三）姿勢控制能力、（四）多人場景、（五）細膩的細節方面展現了其優勢。放大觀看效果最佳。

## 摘要 
可控的人像生成（HIG）在現實生活中有許多應用。最先進的解決方案，如 ControlNet 和 T2I-Adapter，在預訓練的穩定擴散（SD）模型之上引入了一個可學習的分支，該分支可以強制執行各種條件，包括 HIG 的骨架引導。雖然這種即插即用的方式非常有吸引力，但由於來自凍結 SD 分支生成的原始圖像與給定條件之間不可避免且不確定的衝突，給可學習的分支帶來了重大挑戰，因為該分支的本質是進行圖像特徵編輯以強制符合條件。

在本研究中，==提出了一種用於可控人像生成（HIG）的原生骨架引導擴散模型，稱為 HumanSD。==與其使用雙分支擴散進行圖像編輯，我們==透過創新的熱圖引導去噪損失來微調原始的穩定擴散（SD）模型。==這種策略在模型訓練過程中有效且高效地強化了給定的骨架條件，同時減輕了災難性遺忘的影響。HumanSD 是基於三個大規模以人像為中心的數據集進行微調，其中兩個數據集是在本研究中建立的，這些數據集包含文本、圖像和姿勢信息。如圖 1 所示，HumanSD 在精確的姿勢控制和圖像質量方面優於 ControlNet，尤其是在給定的骨架指引較為複雜時表現更為突出。

## 1. 引言  
==可控人像生成（HIG）的目標是在給定條件下生成以人為中心的圖像，例如人體姿勢 [24, 33, 46]、身體解析 [47, 57] 以及文本 [19, 36, 43]。==這項技術有許多應用（例如動畫/遊戲製作 [29] 和虛擬試穿 [56]），因此吸引了學術界和業界的廣泛關注。儘管基於生成對抗網絡（GANs）[10,23–26,33,44,51,54] 和變分自編碼器（VAEs）[7, 14, 34, 46] 的早期可控 HIG 解決方案已成功應用於某些場景（如虛擬試穿），但由於訓練難度高以及多模態融合和對齊能力差 [52]，它們並未獲得主流認可。最近，擴散模型 [12, 35, 40] 展現了前所未有的文本到圖像生成性能 [32]，並迅速成為這個令人興奮領域的主導技術。然而，透過文本信息提供精確的姿勢控制是困難的，尤其是對於像人類這樣的可變形物體。

為了解決上述問題，文獻中提出了兩個同時出現的可控擴散模型：ControlNet [53] 和 T2I-Adapter [27]。這兩個模型在凍結的預訓練穩定擴散（SD）模型 [35] 之上引入了一個額外的可學習擴散分支。這個額外的分支使圖像生成過程中能強制執行各種條件，例如骨架和草圖，從而在可控性方面大大提升了原始 SD 模型，並因此在社群中獲得了廣泛的關注。

然而，在這樣的雙分支擴散模型中，可學習的分支實質上是在執行一項具挑戰性的圖像特徵編輯任務，並且存在多種限制。以骨架引導的可控 HIG 問題為例，該問題旨在生成具有特定姿勢的人像。當給定包含人類活動的文本提示時，SD 分支可能會生成與骨架引導不一致的各種圖像，例如，人類可能會出現在不同的地方，並呈現出各種姿勢。因此，額外的條件分支不僅需要學習如何根據給定的骨架引導生成人像，還需抑制各種不一致性，這使得訓練更加困難，推理過程也變得不穩定。總的來說，骨架引導與凍結的 SD 分支生成的原始圖像之間的差距越大，給定引導與生成的人像圖像之間的差異也越大。此外，這些==雙分支解決方案的推理成本相比原始 SD 模型大幅增加。==

![[PaperWithCode/8-HumanSD/Figure2.png]]
圖 2：概述。 (a) 顯示了提出的 HumanSD 框架，具有新穎的熱圖引導的去噪損失。給定姿勢條件，我們的模型將相應的骨骼圖像輸入到預先訓練 SD 的 VAE 編碼器中，以獲得姿勢潛在嵌入。然後將嵌入與擴散產生的噪音潛​​在嵌入連接起來並輸入到 UNet 中。在訓練階段，熱圖引導的去噪損失透過增加其在損失函數中的權重，幫助UNet專注於人類所處的特定區域，特別是當人類世代表現不佳時。 (b) 顯示了最近的 SOTA 方法 ControlNet [53]，該方法將 SD UNet 編碼器加倍用於條件提取並凍結原始 SD 分支以保持圖像生成能力。

相比於使用額外的可訓練分支來進行可控人像生成（HIG），本研究提出了一種原生的骨架引導擴散模型，名為 HumanSD。==通過將骨架條件與有噪聲的潛在嵌入結合，並直接微調 SD 模型 [35]，==如圖 2（a）所示，HumanSD 能夠原生地引導圖像生成，達到所需的姿勢，而不需要進行具有挑戰性的圖像編輯任務。為了減輕在微調過程中因模型過擬合導致的災難性遺忘效應，我們提出了一種創新的熱圖引導去噪損失，該方法能在訓練階段將有條件的人像與無條件的背景分離開來。這種分離使微調過程集中於前景人物的生成，並且盡量減少對預訓練 SD 模型參數的意外覆蓋，從而避免影響模型的生成和泛化能力。除了算法外，訓練數據也是決定模型性能的另一個重要因素 [38]。為了提高 HumanSD 的 HIG 質量，我們在三個大規模以人像為中心的數據集上微調了我們的模型，這些數據集包含高質量的圖像、相應的2D骨架信息和文本描述：GHI、LAION-Human 和 Human-Art。具體來說，GHI 和 LAION-Human 是本研究中建立的數據集。GHI 包含 100 萬張由 SD 使用精心設計的提示詞生成的多場景圖像，並選擇了其中質量最高的前 30%。LAION-Human 則從 LAION-Aesthetics [37] 中過濾選擇了 100 萬張以人像為中心的圖像。本文的主要貢獻包括：

- 我們提出了一個新的 HIG 框架 HumanSD，使用創新的熱圖引導去噪損失，能夠原生生成具有高度精確姿勢控制的人像，且在推理過程中沒有額外的計算成本。

- 我們引入了兩個大規模的以人像為中心的數據集，具有標準的開發流程，能夠促進多場景 HIG 任務，數據量龐大、分佈豐富且標註質量高。

- 為了證明 HumanSD 的有效性和效率，我們使用了一系列評估指標，涵蓋圖像質量、姿勢準確性、文本與圖像的一致性，以及推理速度，並在公平的實驗設置中將我們的模型與先前的工作進行比較。

綜上所述，HumanSD 在姿勢控制和人像生成質量方面優於當前最先進的解決方案，如 ControlNet，特別是在給定的骨架引導較為複雜的情況下表現更為出色。

## 2. 相關研究

### 2.1. 姿勢引導的人像生成  
在過去二十年中，由於姿勢在動作描述中的有效性 [17, 18, 45, 48–50]，姿勢引導的可控人像生成（HIG）[7,23–26,33,34,44,46,51,54] 受到了學術界和業界的廣泛關注。透過來源圖像和姿勢條件（例如骨架圖像或身體解析），姿勢引導的 HIG 模型可以生成具有來源圖像外觀且符合所需姿勢的擬真圖像。這些算法主要基於 GANs [10, 23–26, 33, 44, 51, 54] 或 VAEs [7, 14, 34, 46]。這些方法專注於自然場景的操作，但由於模型設計的局限性、不適當的條件注入策略以及訓練數據的多樣性不足，無法在跨模態特徵對齊中取得良好的效果，導致使用人工場景來源圖像或任意姿勢輸入時產生不真實且效果不佳的結果。此外，這些模型嚴重依賴難以獲取且缺乏多樣性的來源-目標配對圖像。

與圖像不同，隨著大型視覺-語言模型的興起 [31]，文本成為一種靈活、用戶友好且信息豐富的條件。一些工作涉及使用文本條件來引導 HIG，但受限於小規模詞彙庫，無法在開放詞彙情境下成功運作 [19,36,43]。在近期的研究中，ControlNet [53]、T2I-Adapter [27] 和 GLIGEN [15] 引入了增加任意條件的方法。ControlNet 和 T2I-Adapter 為預訓練的文本到圖像擴散模型 [35] 添加了額外的可訓練模組。由於其設計目標是通用框架，這些方法無法針對具有多樣姿勢、細緻身體部位、風格、視角、大小和數量的圖像進行精準處理。此外，它們的模型在可訓練和凍結分支間存在衝突，導致姿勢控制能力不足。相比之下，HumanSD 在人像姿勢控制上效率高且精度高，專為開放世界多場景的 HIG 設計。

## 2.2. 人像生成數據集  
目前的 HIG 數據集，如 iDesigner [9]、DeepFashion [22]、Market1501 [55] 和 MSCOCO [18]，主要集中在現實場景中的人像生成，並提供了噪聲較多的來源-目標配對圖像。這些主流數據集場景有限（如穿搭、街拍），無法推廣到其他場景，如卡通、油畫和雕塑。

最近，Human-Art [13] 提供了 50,000 張以人為中心的圖像，涵蓋五個自然場景和十五個人工場景，並附有精確的姿勢和文本標註。Human-Art 專為多場景人像任務設計，適合用於驗證現有生成方法的質量和多樣性。然而，Human-Art 的數據規模有限，不足以進行大型模型訓練。Laion5B [37] 是一個公開的數據集，擁有足夠的文本-圖像配對數據，但包含許多與人無關的圖像。ControlNet [53] 採用了人體姿勢估計工具 OpenPose [5]，對從網絡抓取的圖像進行處理，收集了 20 萬個姿勢-圖像-文本配對，其中大多數是現實場景的圖像。使用這些數據進行訓練將導致對現實場景的顯著偏倚，且多樣性不足。

本研究提供了一個針對骨架引導 HIG 的大規模多場景文本-圖像-姿勢數據集的標準開發流程，解決了缺乏適當訓練和測試數據集的問題。


## 3. 預備知識與動機

本節介紹近期基於SOTA SD的HIG方法中的衝突細節，並在第4節概述設計HumanSD的動機。這些方法（特別是ControlNet和T2I-Adapter）使用潛在擴散模型（LDM [35]）作為基礎，因其具有高度可訓練性和高生成質量，我們將在第3.1節介紹該模型。然後，第3.2節闡述ControlNet和T2I-Adapter中的衝突。由於這兩個模型設計相似，我們以ControlNet為例。

### 3.1. 預備知識 - 潛在擴散模型  
LDM，更廣為人知的是穩定擴散（SD），是一種在潛在嵌入空間上進行的擴散模型 [39]，而不是直接作用於圖像。圖像被VAE投影到潛在嵌入中，然後在潛在空間中由文本條件引導。LDM的潛在空間損失函數與普通擴散模型 [12, 40] 類似，表達式如下：  

$$L_{{\mathrm{LDM}}}=\underset{t,z,\epsilon}{\operatorname*{\operatorname*{\mathbb{E}}}}\left[\left\|\epsilon-\epsilon_{\theta}\left(\sqrt{\bar{\alpha}_{t}}z_{0}+\sqrt{1-\bar{\alpha}_{t}}\epsilon,c,t\right)\right\|^{2}\right] \tag{1}$$

其中，$z_0$ 為訓練樣本 $x_0$ 的潛在嵌入； $\epsilon_{\theta}$ 和 $\epsilon$ 分別是UNet $\theta$ 估計的噪聲和在相應擴散時間步 $t$ 注入的真實噪聲；$c$ 是生成過程中涉及的所有條件的嵌入；$\bar{\alpha}_{t}$ 是與普通擴散模型中相同的係數。

![[PaperWithCode/8-HumanSD/Figure3.png]]
圖 3：顯示 ControlNet [53] 中兩個分支行為衝突的範例。

### 3.2. 雙分支解決方案中的衝突  
本節我們將對ControlNet [53]的條件添加策略進行更詳細的理論分析。我們認為凍結的圖像生成分支與可訓練的條件注入分支之間的行為衝突導致了姿勢控制能力的下降。如圖3所示，ControlNet是一種即插即用的條件圖像生成方法。它克隆了一個SD分支來從添加的條件中提取層次特徵，並凍結了原始SD分支以保留生成能力。可訓練的神經網絡模塊與凍結的模塊通過卷積層連接。卷積層將可訓練的特徵作為輸入，其輸出與凍結特徵相加。我們將原始和附加SD分支的UNet中特徵分別表示為，其中cT是文本條件，c = cT + cP 是cT和姿勢條件cP的集合。注意，噪聲 $f_\theta^O(z,c_T,t)$  和$f_\theta^A(z,c,t)$ 可以被視為由最後一層UNet輸出的特徵。如圖3所示，$f_\theta^O(z,c_T,t)$  可以根據其與cP的一致性，分為正部分 $f_\theta^{O+}(z,c_T,t)$和負部分$f_\theta^{O-}(z,c_T,t)$，表示如下：  
$$f_\theta^O(z,c_T,t)=f_\theta^{O+}(z,c_T,t)+f_\theta^{O-}(z,c_T,t) \tag{2}$$
對於帶有文本和姿勢引導的雙分支模型，理想的估計特徵 $\bar{f}_\theta$ 應滿足：  
$$\bar{f}_\theta=f_\theta^{O+}(z,c_T,t)+\tilde{f}_\theta^+(z,c,t), \tag{3}$$
其中，$\tilde{f}_\theta^+(z,c,t)$ 確保了細粒度的姿勢控制，這是 $f_\theta^{O+}(z,c_T,t)$ 無法保證的。我們還有：  
$$\bar{f}_\theta=f_\theta^O(z,c_T,t)+f_\theta^A(z,c,t) \tag{4} $$
因此，我們可以得到附加SD分支中的特徵：  
$$f_\theta^A(z,c,t)=\tilde{f}_\theta^+(z,c,t)-f_\theta^{O-}(z,c_T,t) \tag{5}$$
這導致了推理過程中的間接噪聲生成，額外的（可訓練的）分支必須學會如何（1）根據姿勢條件識別估計噪聲的正負部分，（2）抑制負部分，以及（3）生成額外的正部分。凍結的SD分支導致了負部分和額外正部分之間的永久衝突。相反，對於所有參數均可訓練的微調方法，模型經歷了順暢且穩定的訓練過程，自然學會了處理姿勢條件和跨條件的平衡，從而避免了衝突。

## 4. 方法

為了解決先前基於SD方法中的衝突問題，我們提出HumanSD，一種原生的骨架引導擴散模型，用於精確且高效的多場景人像生成。傳統的微調面臨災難性遺忘和過度擬合的問題。為了解決這一問題，我們提出了一種帶有新穎損失函數的條件添加策略，詳見第4.1和第4.2節。最後，我們在第4.3節中介紹了多場景以人為中心的圖像生成數據集構建過程。

### 4.1. 骨架條件添加  
如圖2（a）所示，我們提出的==HumanSD使用與輸入圖像相同大小的骨架圖像來添加姿勢條件，提供明確的位置信息。==為了將姿勢條件與輸入圖像的潛在嵌入對齊，骨架圖像會經過VAE編碼器處理。與文本條件不同，我們並未在每個UNet模塊中通過注意力添加姿勢的潛在嵌入，而是直接將其與有噪聲的潛在嵌入拼接在一起。這確保了相同密度級別的信息在同一階段處理，從而改善了結構信息的整合。

### 4.2. 熱圖引導去噪損失  
對深度神經網絡進行無保護的微
調很容易導致災難性遺忘，當學習新任務時，先前任務的性能會急劇下降。直接用新數據和新條件微調擴散模型也會導致相同的問題（例如Anything Model [1]，該模型從SD微調生成動畫圖像，無法生成其他風格的圖像）。這種性能下降部分是由於對圖像所有像素進行無差別學習造成的。對於具有全局信息的條件（如一般文本描述），這在某種程度上是合理的。然而，對於具有局部結構信息的條件（如具有具體位置信息的姿勢條件），對整個圖像進行微調會導致條件不變區域（如背景）的質量下降。

為了解決此問題，我們提出了熱圖引導的去噪損失，當添加新的結構感知條件時，在保護模式下對擴散模型進行微調。這種方法特別關注於新添加條件的訓練，並將圖像中與條件無關的部分交由預訓練的主幹網絡處理，從而在生成質量和條件圖像一致性方面達到高性能。熱圖引導的去噪損失通過顯式地將聚合熱圖權重$W_a$添加到原始擴散模型的損失函數中來發揮作用。損失函數由方程9修改為方程6。

$$L_{\mathrm{h}}=\mathbb{E}_{t,z,\epsilon}\left[\left\|W_a\cdot\left(\epsilon-\epsilon_\theta\left(\sqrt{\bar{\alpha}_t}z_0+\sqrt{1-\bar{\alpha}_t}\epsilon,c,t\right)\right)\right\|^2\right] \tag{6}$$

最直接的$W_a$設計之一是為與條件更相關的特徵像素賦予更大的優先權因子。然而，擴散是一個逐步添加噪聲的過程，並非所有步驟對條件注入都是必須的。因此，在所有步驟中分配一個恆定的權重圖可能會破壞訓練過程。因此，我們需要（1）找出模型在不同步驟和階段分別學習了什麼，以及（2）根據逐步模型行為確定權重函數$W_a(t)$。圖4的第一行顯示了不同步驟中解碼的有噪潛在變量；第二行顯示了估計噪聲與其在擴散過程中確定的真實值之間的差異；第三行顯示了由預訓練的人體姿勢熱圖估計器 [6] 根據噪聲差異生成的相應熱圖。使用熱圖作為$W_a$的描述，擴散模型可以更集中地學習條件（人體姿勢）處理。更詳細的熱圖引導去噪損失的實現可見於圖2（a）。

![[PaperWithCode/8-HumanSD/Figure4.png]]
圖 4：解釋不同擴散步驟中 $W_a$ 計算的圖示。

### 4.3. 數據集構建過程

擴散模型需要大量數據進行訓練和微調。為了確保圖像場景、人類行為和外觀的多樣性，我們引入了一個標準數據集開發流程，並構建了兩個大規模數據集：GHI 和 LAION-Human。圖5展示了每個數據集的示例和特徵。

![[PaperWithCode/8-HumanSD/Figure5.png]]
圖 5：所用資料集 GHI、LAION-Human 和 Human-Art 的範例和特徵 [13]。

**GHI**：GHI 是 Generated Human Images 的縮寫。直接從 SD 的學習分佈中抽取數據是一種維持 SD 生成能力且不引入新數據分佈的好方法。為了最大限度地利用 SD 的潛在圖像可能性，我們運用了提示工程 [21, 28]，設計了由18個子提示部分構成的提示詞，這些部分包括圖像場景風格、人數、人類特徵、行為和背景描述（例如，一幅寫實的像素藝術作品，兩個美麗的年輕女孩在巴黎街頭夜晚冬天奔跑，64K，一件大師之作）。我們使用在 Human-Art 上訓練的姿勢估計器 [6] 來檢測多樣場景中的人物姿勢，並根據檢測結果過濾出人數錯誤、多人手臂和腿部 [7]、以及身體完整度低的圖像。該篩選策略確保 GHI 包含相對乾淨的文本和姿勢註釋，並提高圖像質量。最終，GHI 包含 100 萬個姿勢-圖像-文本配對，包括14個場景（來自 Human-Art）和6826種人類行為（來自 BABEL [30]、NTU RGB+D 120 [20]、HuMMan [4]、HAA500 [8]、和 HAKE-HICO [16]），每張圖像中的人數比例為 7:2:1，包含一至三人。

**LAION-Human**：類似於 ControlNet [53] 和 T2I-Adapter [27]，我們構建了一個包含大規模網絡圖像的數據集 LAION-Human。我們從 LAION-5B [37] 中收集了約 100 萬個圖像-文本配對，並根據高圖像質量和高人類估計置信分數進行篩選。相比於 ControlNet 和 T2I-Adapter，我們採用了一個通用的姿勢估計器，該估計器經過 Human-Art 的訓練，能夠選擇更多樣的圖像，如油畫和卡通。更重要的是，LAION-Human 包含比 ControlNet 和 T2I-Adapter 使用的數據更豐富的人類行為和更多寫實圖像。

**Human-Art**：Human-Art [13] 包含 5 萬張圖像，涵蓋 20 種自然和人工場景，並且有乾淨的姿勢和文本註釋，能夠為訓練和定量評估提供精確的姿勢和多場景數據。我們遵循 Human-Art 的設置將數據集分為訓練集和測試集。除非另有說明，我們將 HumanSD 訓練在 GHI、LAION-Human 和 Human-Art 的訓練集（以下部分稱為 Union）上，並在 Human-Art 的驗證集上進行測試。

## 5. 實驗

在本節中，我們驗證了HumanSD在骨架引導的HIG中，相較於當前SOTA的SD方法（第5.2節）和GAN方法（第5.3節）表現優異，使用第5.1節中解釋的8個評估指標。第5.4節提供了關於熱圖引導去噪損失、訓練數據集和訓練迭代的消融研究。實現細節請參見補充材料。

### 5.1. 評估指標  
為了說明我們提出的HumanSD的有效性和效率，我們使用涵蓋四個方面的八個指標：圖像質量、姿勢準確性、文本圖像一致性和推理時間。  
**圖像質量**：我們報告了Fréchet Inception Distance（FID [11]）和Kernel Inception Distance（KID [3]），這些指標廣泛用於衡量合成圖像的質量。具體而言，我們在每個HumanArt場景上評估FID和KID，並報告平均值，該值反映了生成質量和多樣性。  
**姿勢準確性**：我們採用了基於距離的平均精度（AP）[18]、基於姿勢餘弦相似度的AP（CAP）和人數計算誤差（PCE）[7]。這些指標衡量給定的姿勢條件與從生成圖像中提取的姿勢結果之間的差異。基於距離的AP評估生成姿勢與真實值之間的關鍵點距離。我們還為中等尺寸的人物提供了AP(m)（圖像分辨率從322到962，遵循MSCOCO [18]）。我們通過將AP中的距離誤差替換為正規化的餘弦相似度誤差來計算CAP，以評估給定姿勢與生成姿勢之間的位置對齊相似度。CAP消除了絕對位置的影響，專注於純粹的動作相似性。PCE測量給定骨架數量與生成人物數量之間的差異，對多人圖像生成進行了有效評估，並部分反映了單人圖像生成中的不一致情況，例如錯誤的頭、手臂和腿數量。  
**文本圖像一致性**：CLIP [31] 相似度（CLIPSIM [42]）評估生成圖像與相應文本提示之間的文本圖像一致性。CLIPSIM將文本和圖像投影到同一共享空間中，並評估其嵌入的相似性。  
**推理時間**：我們在一個NVIDIA A100 80G上測試每張圖像的推理時間，以評估效率。結果是在批次大小為1的20次隨機運行中取平均值。

### 5.2. 與基於SD的方法的比較  
我們將HumanSD與近期SOTA模型ControlNet [53]和T2I-Adapter [27]進行比較。為確保公平，我們報告了在我們提出的LAION-Human子集上訓練的結果，包括0.2百萬（0.2M）張圖像，數據分佈與ControlNet和T2I-Adapter的訓練數據集相似，如表1所示。

![[PaperWithCode/8-HumanSD/Table1.png]]
表 1：HumanSD 與其他基於 SD 的模型之間的定量比較（公平比較）。 HumanSD 在從 LAION-Human 中隨機選擇的 0.2M 文字-圖像-姿勢對上進行了大約 300 個 GPU 小時（95K 次迭代）的訓練，類似於 T2I-Adapter 和 ControlNet。結果證明了 HumanSD 的有效性和效率。

HumanSD在姿勢可控性方面的優越性通過其在姿勢相關指標上的顯著性能提升得到了驗證。與ControlNet和T2I-Adapter的最佳結果相比，HumanSD（0.2M）在姿勢準確性（如AP、AP(m)和PCE）上表現提升了34.8%至109.1%。這種性能提升來自於更好的條件注入和熱圖引導去噪損失。結果解釋了第3.2節中提到的ControlNet中不可避免的衝突。正如之前所述，由於這些衝突，ControlNet可能經常受到凍結分支中存在的負面特徵的干擾，無法忠實呈現給定的姿勢。而HumanSD的原生生成過程和熱圖引導去噪損失簡化了姿勢引導，並確保了生成質量。圖1 I 和圖1 III 進一步展示了HumanSD在處理複雜姿勢時的專長。

具體而言，由於文本提示幾乎無法指示每個人生成的位置（對應於指標AP）和大小（對應於指標AP(m)），因此在ControlNet和T2I-Adapter中，文本引導的凍結分支與姿勢感知的可訓練分支之間存在巨大的行為差距。這一點通過SD在AP和AP(m)上的幾乎為零的得分得到了驗證。因此，ControlNet和T2I-Adapter無疑面臨與這些屬性相關的嚴重衝突。不幸的是，隨著條件或場景複雜性的增加，這些衝突加劇了（如圖1 IV所示）。這一點通過PCE反映出的ControlNet在多人生成上的表現比SD更差得到了驗證。

此外，由於其單分支設計，HumanSD相比於ControlNet和T2I-Adapter推理速度更快。儘管T2I-Adapter使用了一個比ControlNet更高效的可訓練分支，但引入一個額外的條件學習分支仍然耗時。其條件學習分支的壓縮也導致了與ControlNet相比質量的下降，如表1所示。

對於CAP，ControlNet中的干擾可能是微不足道的，因為文本提示和骨架圖像給出的姿勢信息可能非常相似（例如，文本“站立”可能與實際站立人物的骨架非常相似）。因此，即使沒有姿勢條件，SD也能達到一定水平的CAP，HumanSD在CAP上的提升相對較小。

在圖像質量方面，這三個模型表現出相似的FID和KID，表明它們都能夠保留SD的基本圖像生成和文本理解能力。HumanSD通過在微調中專注於特定的人體區域實現了這一性能，而ControlNet和T2I-Adapter則通過其凍結的SD分支實現。SD在風格方面的FID和KID得分相對最差，表明文本信息在指導高質量和多樣性的人像生成時表現不佳。

然而，HumanSD和ControlNet在文本圖像一致性方面均表現出下降。這種微不足道但存在的退化源於文本與姿勢條件之間的潛在不一致性。這表明HumanSD和ControlNet在生成過程中都將姿勢優先於文本。

### 5.3. 與基於GAN的方法的比較  
本節展示了先前基於GAN的HIG方法在精確且多樣化的姿勢控制方面的不足。我們比較了神經紋理提取與分佈（NTED [33]）和文本誘導姿勢合成（TIPS [36]），這兩者都是無文本的姿勢引導真實場景圖像生成方法。對於NTED和TIPS，我們使用隨機選自DeepFashion [22]的圖像作為來源圖像輸入，並使用Human-Art驗證集中的骨架圖作為姿勢條件。對於HumanSD，我們使用Human-Art驗證集中的文本和圖像。

正如圖6所示，NTED和TIPS在面對非傳統姿勢條件時容易失敗。具體來說，NTED和TIPS在未訓練的姿勢輸入下的AP分數分別為2.79和17.65。因此，我們可以得出結論，先前基於GAN的HIG方法不適用於開放場景的姿勢控制。這也反映了HumanSD在精確姿勢控制和多場景生成能力上的重要性。

![[PaperWithCode/8-HumanSD/Figure6.png]]
圖 6：在給定非常規姿勢條件的情況下，先前的方法 NTED 和 TIPS 產生的範例。

### 5.4. 消融研究  
本節展示了除了更好的條件注入允許更自然的生成並避免衝突外，所提出的熱圖引導去噪損失也有助於HumanSD的更好表現。我們還探討了所提出的訓練數據集和訓練迭代次數如何影響最終結果。除非另有說明，該模型在Union數據集上訓練約300 GPU小時（9.5萬次迭代）。

**熱圖引導去噪損失的影響**  
如表2所示，添加熱圖引導的去噪損失有助於反向傳播集中於優化與人像生成更相關的權重。這進一步帶來了更精確的人體姿勢引導，從而將AP分數從30.63提高到32.66。同時，專注於人像生成還改善了背景的保留，從而使與文本描述無關的圖像信息更為相關，這使得CLIPSIM從32.55增加到32.98。

![[PaperWithCode/8-HumanSD/Table2.png]]
表 2：損失函數的消融。

圖7顯示了熱圖引導去噪損失影響的定性可視化。熱圖引導的去噪損失有助於更精確的姿勢可控性（II(c), II(f)）、更好的人體細節保真度（I(c), II(c)）、改進的文本圖像一致性（I(c), II(f)）以及增強的背景質量（I(c), I(f), II(c), II(f)）。值得注意的是，HumanSD還能生成如機器人和動物等類人形的優秀結果（I(f)）。

![[PaperWithCode/8-HumanSD/Figure7.png]]
圖 7：包含和不包含熱圖引導的去噪損失的生成結果的可視化。

**訓練數據集的影響**  
為了證明所提出的數據集的有效性，我們提供了三種訓練數據集設置的結果。如表3所示，僅使用GHI訓練能保證生成具有最準確的人數和更強的文本圖像一致性。這主要歸因於GHI的數據分佈與SD更好地對齊。然而，由於缺乏真實圖像，僅用GHI訓練的模型生成的結果顯示出較低的生成質量（如模糊的人體肢體、不真實的人體結構），導致AP分數較低。在LAION-Human上訓練能夠實現相對更滿意的AP結果。與LAION-Human相比，結合所有數據集進行模型訓練可以進一步提高AP性能，並通過增加數據多樣性，在PCE和CLIPSIM之間取得更好的平衡。

![[PaperWithCode/8-HumanSD/Table3.png]]
表 3：訓練資料集的消融。資料集的詳細資訊在4.3節中介紹

**訓練迭代次數的影響**  
HumanSD的微調迭代次數對生成結果有顯著影響。在我們的實驗中，性能在約95K次迭代（約300 GPU小時）時達到最佳並開始波動。表4展示了50K、95K和150K次迭代的訓練結果。

![[PaperWithCode/8-HumanSD/Table4.png]]
表 4：微調迭代的消融。

## 6. 結論  
在本研究中，我們提出了一個新的框架HumanSD，基於預訓練的SD，用於高度精確的姿勢和文本條件人像生成。為了專注於前景人物的生成並保留預訓練SD的生成能力，我們提出了一種創新的熱圖引導去噪損失。此外，我們引入了包含超過200萬對文本-圖像-姿勢配對的大規模以人為中心的數據集，用於多場景的人像生成學習。最後，我們在涵蓋圖像質量、姿勢準確性和文本圖像一致性的一系列評估指標上，將HumanSD與先前的模型進行了比較。結果證明了我們提出的方法和數據集的有效性和效率。

儘管HumanSD在HIG的可控性方面取得了進展，但仍然存在一些限制。（1）在生成極度擁擠的場景和複雜/罕見的動作時，HumanSD仍然容易失敗。（2）儘管我們對數據進行了篩選，但訓練使用的大規模文本-圖像-姿勢配對數據中可能仍然包含社會偏見和暴力內容。（3）評估系統尚不夠全面和完善。

在未來的工作中，我們計劃解決上述限制，以實現更好的可控HIG。最後，我們希望本研究能激發未來的研究，重點關注更高的可控性、更豐富的人像場景、更多的條件和更好的圖像質量的HIG。