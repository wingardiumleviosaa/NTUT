## 摘要  
自我監督學習已被證明對基於骨架的人類行為理解有效，這是一個重要但具有挑戰性的課題。先前的研究主要依賴對比學習或遮蔽運動建模來建模骨架關係。然而，這些方法無法有效且同時處理序列層級和關節層級的表徵學習，導致所學得的表徵無法泛化到不同的下游任務。此外，簡單地將這兩種範式結合，未能挖掘出它們之間的協同作用，並可能在訓練中引起干擾。為了解決這些問題，我們提出了名為「PCM3」（Prompted Contrast with Masked Motion Modeling）的通用3D行為表徵學習方法。我們的方法將對比學習與遮蔽預測任務以互惠的方式整合，大幅提升了對各種下游任務的泛化能力。具體來說，遮蔽預測為對比學習提供了新的訓練視角，而對比學習則用高層次的語義信息引導了遮蔽預測的訓練。此外，我們提出了雙重提示的多任務預訓練策略，透過減少學習這兩種不同預訓練任務時產生的干擾，進一步改善了模型的表徵。基於三個大規模數據集，我們在五個下游任務上進行了廣泛的實驗，展示了PCM3相較於最先進的研究作品在泛化能力上的優勢。我們的項目公開於：https://jhang2020.github.io/Projects/PCM3/PCM3.html。


## 1 引言

人類活動理解是一個多媒體處理中的關鍵問題，因其在現實生活應用中扮演著重要角色，例如人機互動 [18]、醫療保健 [25] 和自動駕駛 [2]。作為人類活動理解的一種高效表徵，3D 骨架通過人體關鍵關節的 3D 座標來表示人體形態。與其他表徵方式（如 RGB 視頻和深度數據）相比，骨架具有輕量化、緊湊性和隱私保護等優勢。由於這些競爭優勢，骨架已廣泛應用於人類行為分析中。

許多研究已經致力於基於監督學習的骨架行為學習 [6, 9, 35, 47]。然而，這些方法的性能嚴重依賴於大量的標註數據，而這些標註數據的收集既耗時又昂貴。這一全監督學習方法的內在缺陷限制了其在現實世界中的應用。因此，越來越多的研究開始關注自我監督的 3D 行為表徵學習，從無標註數據中學習有意義的特徵。

自我監督的 3D 行為表徵學習主要集中在兩種範式上：基於重建的方法和基於對比學習的方法。基於重建的方法利用編碼器-解碼器架構，通過預測遮蔽的骨架（即遮蔽建模）或重建原始數據來學習表徵。這些方法側重於關節層級的特徵建模，並捕捉時空關係。相比之下，基於對比學習的方法通過數據增強構建正負樣本對，並應用實例區分任務來學習序列層級的語義特徵。

然而，值得注意的是，最近的大多數表徵學習方法專注於單一範式來建模關節層級（通過遮蔽骨架建模）[45, 53] 或序列層級（通過對比學習）[8, 20, 26, 52] 的特徵。因此，這些方法難以在不同的下游任務中很好地泛化，例如識別任務和運動預測，因為它們無法同時有效地學習不同粒度的表徵。儘管一些研究 [21, 40, 43] 致力於結合上述兩種方法以學習更豐富的表徵，但僅取得了中等的改進。這是因為簡單地結合這兩種方法忽略了遮蔽預測與對比學習特徵建模機制之間的差異，未能充分利用其潛在的協同作用。這些問題限制了模型的泛化能力，使得通用的 3D 行為表徵學習成為一個具有挑戰性的且未被充分探索的領域。

為了解決這些問題，我們提出了帶有遮蔽運動建模的提示對比學習（PCM3），該方法探索了上述兩種範式之間的相互協作，以實現通用的 3D 行為表徵學習，如圖 1 所示。具體來說，首先提出了精心設計的內部和外部對比學習以及基於拓撲的遮蔽骨架預測作為基本流程。此外，我們將這兩個任務連接起來，探索它們之間的協同作用。遮蔽預測訓練中的視角被用作對比學習的新穎正樣本。反過來，遮蔽預測分支也通過來自對比學習分支的梯度更新，以獲得更高層次的語義指導。同時，為了減少不同預訓練任務和數據視角之間的學習干擾，我們提出了雙提示多任務預訓練策略。兩種類型的提示，即領域特定提示和任務特定提示，被應用來明確指導模型從不同的數據視角和任務中學習。


![](./Figure1.png)
圖 1：提出的多功能動作表示學習方法的插圖。我們以互惠互利的方式整合了對比學習和掩蔽骨架建模範式。掩蔽預測為對比學習提供了新的視圖（藍色箭頭），生成的對比梯度（綠色箭頭）反過來作為掩蔽預測的高級語義指導，對關節級別和序列級別的特徵進行建模。


我們在五個下游任務上進行了廣泛的實驗，為該方法進行了全面評估。相比於最先進的方法，我們提出的方法展現了出色的泛化能力。我們的貢獻可以總結如下：

- 我們提出了 PCM3 以實現多粒度的表徵，將遮蔽骨架預測和對比學習範式以互惠的方式結合。我們通過遮蔽預測網絡生成更多樣化的正運動視角來進行對比學習。同時，生成的梯度被傳播並用高層次的語義信息引導遮蔽預測學習。
- 考慮到不同的數據視角和預訓練任務可能會引起相互干擾，我們引入了領域特定提示和任務特定提示來進行多任務預訓練。這些可訓練的提示使模型能夠為不同的骨架生成更具區分性的表徵。
- 我們進行了嚴格的定量實驗，評估了最先進的自我監督 3D 行為表徵學習技術在五個下游任務中的泛化效果，包括識別、檢索、檢測和運動預測，並涵蓋了未損壞和損壞的骨架數據。我們的研究為研究社群提供了一個全面的基準，我們相信這能為該領域的未來研究提供有價值的見解和幫助。


## 2 相關工作

### 2.1 基於骨架的動作識別

隨著深度學習的巨大進展，基於循環神經網絡（RNN）、卷積神經網絡（CNN）、圖卷積神經網絡（GCN）和變壓器（Transformer）的方法被廣泛應用於基於骨架的動作識別。RNN 已經被廣泛用來建模時間依賴性，並捕捉骨架動作識別中的運動特徵。研究 [9] 中使用 RNN 將骨架視為序列數據來處理。隨後，Song 等人 [37, 38] 提出了利用注意力機制和多模態信息來增強特徵表徵。其他一些研究 [15, 24] 將每個骨架序列轉換為類似圖像的表徵，並應用 CNN 模型來提取時空信息。近年來，基於 GCN 的方法由於人體的自然拓撲結構，吸引了更多的關注。許多研究 [6, 35, 47] 將 GCN 應用於空間和時間維度 [47]，並在監督學習的骨架動作識別中取得了顯著成果。同時，由於變壓器模型 [29, 36] 能夠通過注意力機制學習長距離的時間依賴性，也展示了有前景的結果。

然而，這些監督學習方法依賴於大量的標註數據來訓練模型。在本文中，我們探討的是自我監督的 3D 行為表徵學習。

### 2.2 基於骨架的對比學習

對比學習 [3, 4, 14] 已經被證明在骨架表徵學習中具有良好效果。一個受歡迎的研究方向是骨架數據的增強方法，這對所學表徵的質量至關重要。Guo 等人 [12] 探討了在當前對比學習管道中使用極端增強方法。Zhang 等人 [52] 提出了層次一致性對比學習，利用了更強的增強技術。另一個研究角度是探索骨架中不同視角的知識。ISC [41] 採用了圖像、圖結構和序列表徵的跨對比學習方式。Li 等人 [20] 利用了不同骨架模態（如關節、骨骼、運動）挖掘潛在的正樣本，並根據相似度對訓練樣本進行重新加權。Mao 等人 [26] 在不同視角之間進行了互相蒸餾。與上述工作不同的是，我們提出將遮蔽建模預訓任務與對比學習相結合，對關節層級和序列層級的特徵進行建模，以實現更通用的表徵學習。

### 2.3 遮蔽影像/骨架建模

遮蔽建模最早在堆疊去噪自編碼器 [42] 中得到探索，將遮蔽操作視為對原始數據添加噪聲。最近，遮蔽建模在自我監督學習中取得了顯著的成功 [13, 46]，特別是在影像表徵學習領域。對於骨架數據，LongT GAN [53] 直接使用基於自編碼器的模型，並通過附加的對抗訓練策略來優化。一些研究 [21, 40] 應用運動預測預訓任務來學習骨架序列中的時間依賴性。受到遮蔽自編碼器 [13] 的啟發，Wu 等人 [45] 提出了遮蔽骨架自編碼器來學習時空關係。在本文中，我們探索了遮蔽建模與對比學習之間的協同作用，並提出了一種基於拓撲的遮蔽策略，以進一步提升表徵學習的效果。


## 3 提出的方法：PCM3

在本部分中，我們首先描述設計的對比學習流程（第 3.1 節）以及我們提出的基於拓撲的遮蔽建模方法（第 3.2 節）。接著，我們進一步在第 3.3 節中介紹了兩個預訓任務之間的協同探索。提示式預訓練策略和整體模型設計則在第 3.4 節中給出。

### 3.1 骨架對比學習

為了便於理解，根據先前的研究 [1, 3, 14]，對影像/骨架對比學習的典型設計進行了說明，通常包括以下組件：

- **數據增強模塊**：該模塊包含一系列手動的數據轉換，用來構建原始數據的不同視角，這些視角被視為共享相同語義的正樣本。
- **編碼器 $f(·)$**：作為從輸入空間映射到潛在特徵空間的映射函數。
- **嵌入投影器 $h(·)$**：在編碼器 $f(·)$ 之後應用，將編碼後的特徵映射到嵌入空間，在這裡應用自我監督損失。
- **自我監督損失**：旨在最大化正樣本之間的相似度，通過進行特徵聚類操作來獲得區分性表徵空間。

我們的對比學習設計基於 MoCo v2 [4]。具體來說，我們引入了內部和外部骨架變換以及關係知識蒸餾，以幫助模型捕捉多樣的運動模式並提升表徵學習效果。

**1) 骨架內轉換學習**  我們利用以下轉換方法：時間裁剪-重縮放(Temporal crop-resize)、剪切(Shear)、和關節抖動(Joint Jittering)，參考了之前的研究 [26, 41]。具體來說，給定一個骨架序列 $x$，正樣本對  $(s_{\text{intra}}, s')$  通過上述轉換構建。然後，我們通過查詢/鍵編碼器 $f_q(·)/f_k(·)$ 和嵌入投影器 $h_q(·)/h_k(·)$ 分別獲得相應的特徵表徵 $(z_{\text{intra}}, z')$。同時，維護一個記憶隊列 $M$ ，其中存儲了大量負樣本以進行對比學習。我們通過 InfoNCE 目標 [28] 來優化整個網絡：

$$
\mathcal{L}_{Info}^{Intra}=-\log\frac{\exp(z_{intra}\cdot z^{\prime}/\tau)}{\exp(z_{intra}\cdot z^{\prime}/\tau)+\sum_{i=1}\exp(z_{intra}\cdot m_{i}/\tau)},  \tag{1}
$$

其中，$m_i$ 是對應於第 $i$ 個負樣本在記憶隊列 $M$ 中的特徵，$\tau$  是溫度超參數。在每個訓練步驟後，批次中的樣本將按照先進先出策略被更新到記憶隊列中作為負樣本。鍵編碼器是查詢編碼器的動量更新版本，即：$\theta_k \leftarrow \alpha\theta_k + (1 - \alpha)\theta_q$，
其中 $\theta_q$ 和 $\theta_k$ 分別是查詢編碼器和鍵編碼器的參數， $\alpha \in [0, 1)$ 是動量係數。

其中mi是對應於第 i 個負樣本的 M 中的特徵，τ 是溫度超參數。在訓練步驟之後，根據先進先出策略，批次中的樣本將更新為 M。鍵編碼器是查詢編碼器的動量更新版本，即 θk ← αθk + （1 − α）θq，其中 θq 和 θk 是查詢編碼器和鍵編碼器的參數，α ∈ [0， 1） 是動量係數。

**2) 骨架間轉換學習**  受混合增強技術在自我監督學習中的成功應用啟發 [17, 19, 34, 49]，我們將 $CutMix$ [48]、$ResizeMix$ [31] 和 $Mixup$ [50] 引入到骨架對比學習中。這些骨架間轉換使用兩個不同的樣本來生成混合增強視角。具體來說，給定兩個骨架序列 $s_1, s_2$，我們隨機選擇一種混合方法並獲得混合骨架數據 $s_{\text{inter}}$，具體如下：

- **Mixup [50]**：我們根據採樣的混合比例 $\lambda$ 插值兩個骨架序列，即：$s_{\text{inter}} = (1 - \lambda) s_1 + \lambda s_2$
- **CutMix [48]**：兩個骨架序列的隨機選定區域在時空維度上被剪切並粘貼，並且 \( \lambda \) 定義為替換的關節數量與總關節數量的比率。
- **ResizeMix [31]**：這與 $CutMix$ 類似，但首先在時間維度上對 $s_2$ 進行降採樣，然後再進行混合。

隨後，我們可以通過 $z_{\text{inter}} = h_q \circ f_q (s_{\text{inter}})$ 獲得對應於混合數據的嵌入，並優化以下損失函數：

$$
\mathcal{L}_{Info}^{Inter}=-\log\frac{\exp(z_{inter}\cdot z_{inter}^{\prime}/\tau)}{\exp(z_{inter}\cdot z_{inter}^{\prime}/\tau)+\sum_{i=1}\exp(z_{inter}\cdot m_i/\tau)}, \tag{2}
$$

其中：$z'_{\text{inter}} = (1 - \lambda)(h_k \circ f_k (s_1)) + \lambda(h_k \circ f_k (s_2))$

**3) 關係知識蒸餾** 為了進一步在對比學習中提供細粒度的語義一致性監督，我們引入了關係知識自蒸餾損失，用於正樣本對。受到 [26, 44, 52] 的啟發，關係知識被建模為 $z'| z'_{\text{inter}}$ 與記憶隊列 $M$ 中特徵錨點之間的餘弦相似度。關係分佈（即與負錨點樣本的相似性）在每對正樣本之間被強制保持一致。以對應於前述骨架內轉換的嵌入對 $(z_{\text{intra}}, z')$為例，損失表達式為：

$$
L_{\text{Intra\_KL}} = - p(z', \tau_k) \log p(z_{\text{intra}}, \tau_q)
$$
$$
p_j(z, \tau) = \frac{\exp(z \cdot m_j /\tau)}{\sum_{i=1}^{I} \exp(z \cdot m_i /\tau)} \tag{3}
$$

其中 $m_i$ 是記憶隊列 $M$ 中存儲的第 $i$ 個特徵錨點，$\tau_k$ 和 $\tau_q$ 分別是溫度超參數，設置為 0.05 和 0.1。該蒸餾項引入更多錨點來挖掘細粒度且具語義感知的相似性關係 [44]，從而提升表徵的質量。

### 3.2 **遮蔽骨架預測**

為了進一步豐富模型學習到的表徵，我們將遮蔽骨架建模整合到訓練過程中，並將關節層級的特徵學習融入其中。與僅使用實例級區分任務（即對比學習）相比，這進一步提升了模型的泛化能力，尤其是在密集預測下游任務中。

首先，關於遮蔽策略，先前的研究 [45, 53] 使用隨機遮蔽來隨機選擇在時空維度上的遮蔽關節。然而，由於骨架序列具有冗餘性，遮蔽的關節很容易通過複製空間或時間維度中的相鄰關節來推斷，這不利於對骨架中有意義的關係進行建模。為此，我們提出了基於拓撲的遮蔽策略，該策略在身體部位層級進行遮蔽，而非關節層級，即遮蔽軀幹、右手、左手、右腿和左腿。同時，我們將序列在時間維度上分為不同的片段，並在每個片段中遮蔽相同的部位，如圖 3 所示。

基於上述遮蔽策略，我們對原始骨架 $x$ 進行遮蔽，然後將遮蔽後的骨架 $s_{\text{mask}}$ 輸入編碼器 $f_q(·)$，以獲得相應的特徵。為了預測被遮蔽的骨架區域，我們使用解碼器 $\text{dec}(·)$，該解碼器以編碼特徵為輸入，輸出重建的骨架。對於遮蔽區域，我們通過優化原始數據 $x$ 與預測數據 $s_{\text{predict}}$ 之間的均方誤差（MSE）損失：
$$
L_{\text{Mask}} = \frac{1}{N} \sum_{N} ||(x - \text{dec} \circ f_q (s_{\text{mask}})) \odot (1 - M)||_2 \tag{4}
$$
其中， $N$ 是所有被遮蔽關節的數量，$M$ 是二進制遮蔽矩陣，1 和 0 分別對應可見關節和被遮蔽關節。矩陣 $1$  是與 $M$形狀相同的全一矩陣。