
**摘要**

本文介紹了 Ske2Grid，一個用於改進基於骨架動作識別的新的表徵學習框架。在 Ske2Grid 中，我們基於一種新穎的人體骨架網格表示定義了一種常規卷積操作，這是一個通過三個新設計構建和學習的緊湊圖像狀網格片。具體來說，我們提出了一種圖節點索引變換 (GIT)，通過將骨架圖中的節點逐一分配到所需的網格單元來構建常規網格片。為了確保 GIT 是雙射並且豐富網格表示的表現力，學習了一種上採樣變換 (UPT)，用於插值骨架圖節點以填滿整個網格片。為了解決單步 UPT 過於激進的問題，並進一步利用隨著空間大小增長的網格片的表徵能力，我們提出了一種漸進學習策略 (PLS)，它將 UPT 解耦為多個步驟，並通過一個緊湊的級聯設計逐步學習並與多個配對的 GIT 對齊。我們基於流行的圖卷積網絡構建了網絡，並在六個主流的基於骨架的動作識別數據集上進行了實驗。實驗表明，Ske2Grid 在不同基準設置下顯著超越了現有的基於 GCN 的解決方案，且無需任何複雜的調整。代碼和模型可以在 https://github.com/OSVAI/Ske2Grid 上獲取。

## **1. 引言**

隨著3D動作捕捉系統和先進的即時2D/3D姿勢估計算法的快速發展，基於骨架的動作識別越來越受到產業界和學術界的關注。基於骨架的動作識別系統的性能取決於其對動作執行時人體關節之間協調互動的骨架特徵進行建模的能力。傳統方法（Ke et al., 2017；Hu et al., 2019；Qin et al., 2021）集中於設計手工特徵來建模骨架序列的空間結構和時間動態，並使用精心設計的分類器來識別人類動作。早期基於深度學習的方法（Du et al., 2015；Song et al., 2017；Li et al., 2018a）將視頻中的骨架視為時間向量序列，並使用深度遞歸網絡（如 RNN 和 LSTM）來建模骨架動態。近年來，卷積神經網絡（CNN）和圖卷積網絡（GCN）成為基於骨架動作識別研究的主流學習模型。基於 CNN 的方法（Liu et al., 2017；Yan et al., 2019；Duan et al., 2022c）通常將骨架轉換為類似圖像的輸入，並使用 2D 或 3D CNN 進行端到端的特徵提取。基於 GCN 的方法（Yan et al., 2018；Li et al., 2019；Peng et al., 2020）將骨架視為不規則的圖，並根據預定義的圖拓撲結構學習聚合骨架特徵。最近，基於超圖的模型（例如 Hao et al., 2021）也採用骨架圖結構。與通常忽略人體關節間非物理依賴關係的傳統圖模型不同，基於超圖的模型引入局部和全局超邊來編碼更高階的特徵依賴。此外，新興的基於 Transformer 的模型（例如 Zhang et al., 2021；Plizzari et al., 2021；Zhou et al., 2022）仍保留骨架圖結構，將人體的每個關節視為一個 token，並使用空間和時間自注意力機制來捕捉特徵依賴關係。

儘管基於 CNN 和 GCN 的解決方案廣泛應用，但改進骨架動作識別的表徵學習仍是一個具有挑戰性的問題。一方面，基於 CNN 的解決方案受益於常規卷積對高效特徵建模的優勢，但它們僅限於類似圖像的輸入，而將骨架轉換為這種輸入通常會忽略人體關節的關鍵拓撲信息，並在一定程度上犧牲了骨架數據的緊湊性。例如，Luvizon et al.（2018）直接將時間維度、關節和坐標編碼為類似圖像的張量軸。在最近的研究中，Duan et al.（2022c）將骨架表示為由 2D 姿勢估計器獲得的關節熱圖堆疊。此外，類似圖像的輸入在訓練過程中可能被固定，從而降低了骨架在表示動作模式時的靈活性。另一方面，基於 GCN 的解決方案受益於使用骨架關節之間的拓撲關係進行特徵建模。然而，它們依賴於不規則的拓撲結構，並且被迫逐個節點學習不同形狀和獨立的卷積核，缺乏類似於特徵聚合的屬性。此外，圖卷積的感受野通常覆蓋與目標節點具有預定距離的相鄰節點集合，降低了對特徵交互進行建模的效率，特別是在那些積極協調但拓撲上相對遙遠的人體關節之間。

基於這兩點觀察，我們提出了一種新的骨架表示方法，稱為 Ske2Grid，用於動作識別。我們期望它能繼承骨架的非歐幾里得空間佈局，同時使得可以在類似歐幾里得圖像空間中使用常規卷積，並保持緊湊形狀。具體來說，我們從兩個技術視角探討了這一問題。（1）從表示的角度，如何將骨架從不規則的圖轉換為規則的類似圖像的網格片，並同時保持其關鍵拓撲表示能力和動作識別的緊湊性？（2）從網絡的角度，如何保證學習到的網格片比骨架圖在動作表示方面具有更強的表徵能力？對於第一個問題，我們設計了一種新穎的骨架網格表示，通過三個新設計來構建和學習。具體來說，我們通過使用圖節點索引變換（GIT）將骨架圖中的節點一一分配到所需的網格單元來構建一個規則的網格片，這受到最近3D人體姿勢估計工作（Kang et al., 2023）的啟發。為了確保 GIT 是雙射的，並豐富網格表示的表現力，我們提出了一種上採樣變換（UPT），通過調節圖拓撲對骨架圖節點進行插值，以填滿整個網格片。為了進一步利用在增加的空間大小下網格片的表徵能力，我們提出了一種漸進學習策略（PLS），將 UPT 解耦為多個步驟，並通過緊湊的級聯設計逐步學習並與多個配對的 GIT 對齊。

## **2. 相關工作**

**基於 CNN 的骨架動作識別**  
受圖像任務研究進展的啟發，將圖結構的骨架轉換為類似圖像的輸入，並利用圖像識別管道來處理基於骨架的動作識別任務，成為一個自然的思路。這類方法透過在空間和時間上結合骨架特徵，獲得一系列2D數組，然後將這些2D數組直接轉換為灰度圖像。例如，Ke等人（2017）將骨架轉換為由計算得出的時空特徵表示的多幀片段，並使用深度CNN來建模骨架的長期時間動態。Luvizon等人（2018）則直接將時間維度、關節和坐標編碼為類似圖像的不同軸，並使用基於CNN的多任務框架進行姿勢估計和動作識別。Duan等人（2022c）使用2D姿勢估計器獲得的骨架關節熱圖作為輸入，並利用3D卷積神經網絡進行動作識別，在許多骨架動作識別基準上刷新了最新狀態。這些解決方案受益於規則的2D/3D卷積來進行高效的圖像特徵建模。然而，將骨架轉換為類似圖像的輸入通常會忽略人體關節的關鍵拓撲信息，並在某種程度上犧牲了骨架數據的緊湊性。此外，類似圖像的輸入在訓練過程中通常是固定的。與此不同的是，我們構建並學習了一種緊湊的骨架網格表示，並且其佈局反映了人體關節的拓撲關係，用於動作建模。

**基於 GCN 的骨架動作識別**  
骨架可以自然地表示為一個不規則的圖，其中節點代表關節坐標，邊則自然地連接人體的關節。GCN 將 CNN 泛化到任意結構的圖，是處理圖結構骨架數據的主流學習模型。STGCN（Yan等，2018）將 GCN 擴展到空間-時間圖模型，並設計了用於骨架建模的卷積核，這是第一個在大規模骨架動作識別基準上取得滿意性能的工作。然而，它根據人體結構使用預定義的拓撲，該拓撲在訓練和測試階段都是固定的。隨後的許多方法通過構建具有動態拓撲的骨架圖來改進 ST-GCN（Duan等，2022a；Shi等，2019；2020）。許多最近的方法通過引入額外的上下文信息來增強圖卷積的感受野。AS-GCN（Li等，2019）引入了一個A-link模塊來捕捉特定於動作的潛在依賴性，並使用S-link模塊來表示骨架圖的高階節點依賴性。CA-GCN（Zhang等，2020）通過整合來自整個骨架圖的信息來為每個頂點引入上下文項，以擴大圖卷積的感受野。Shift-GCN（Cheng等，2020）提出了局部移動圖操作和非局部移動圖操作，為空間和時間圖提供靈活的感受野。CTR-GCN（Chen等，2021）提出同時學習共享拓撲和通道特定相關性，獲得通道級拓撲，從而改進圖卷積中的特徵聚合。儘管這些解決方案取得了進展，它們仍使用標準的圖卷積來建模不規則的骨架圖。正如前面所討論的，我們在我們可學習的網格片上定義了規則的卷積操作，用於高效地建模骨架特徵的交互。


## **3. 方法**

在這一部分中，我們首先從一般角度回顧圖卷積，然後定義基於我們網格補丁的卷積操作以及 Ske2Grid 中的三個核心設計，最後介紹網路的構建。

### **3.1. 圖卷積**

考慮一個骨架圖 $G = \{V, E, A\}$，它由一組節點 $V$ 和邊 $E$ 組成，其中節點數量 $|V| = N$，邊數量$|E| = M$，鄰接矩陣 $A \in \{0, 1\}^{N \times N}$。如果節點 $v_i$ 和 $v_j$ 之間存在一條邊，則 $A(i, j) = 1$，否則$A(i, j) = 0$。我們將圖的對應特徵表示為 $X \in \mathbb{R}^{N \times C}$，其中 $C$ 表示骨架特徵維度，$x_i \in \mathbb{R}^{C \times 1}$ 表示節點 $i$ 的特徵向量。

圖卷積操作在節點 $i$ 處對單通道的輸出值可以寫為：

$$
f_{\text{out}}(v_i) = \sum_{v_j \in B(v_i)} w_{i,j} x_j, \tag{1}
$$

其中 $B(v_i) = \{v_j | d(v_j, v_i) \leq D\}$ 表示節點 $i$ 的鄰居集合，$d(v_j, v_i)$ 表示從節點 $j$ 到節點 $i$ 的最短路徑長度，通常 $D$ 設置為 1；$w_{i,j} \in \mathbb{R}^{1 \times C}$ 是一個特定於節點 $i$ 的權重向量，用於與鄰居集合 $B(v_i)$ 中對應的輸入特徵 $x_j$ 計算內積。

這個卷積操作建模了由圖拓撲定義的一組相鄰節點之間的特徵交互。然而，骨架動作表示的表達能力改進在於它能夠建模一組積極協調的關節之間的區分性特徵交互，這可能需要卷積操作中啟用的鄰居集合更加靈活和富有表現力。

### **3.2. Ske2Grid 中的卷積**

直觀上，可以使圖卷積中的鄰居集合變得可學習，以提高動作表示的表達能力。然而，卷積核是特定於目標節點的，難以對一組變化的節點之間的關聯進行建模。為了解決這個問題，我們在 Ske2Grid 中定義了一個規則的卷積操作。

受到最近 3D 人體姿勢估計進展的啟發（Kang et al., 2023），我們構建了一個規則的網格補丁$D_{H \times W}$，其中 $H$ 和 $W$ 分別是空間的高度和寬度。它由一組網格單元 $d_{i,j}$ 組成，這些單元由骨架圖中的特定節點填充。網格補丁的特徵表示為 $Y \in \mathbb{R}^{H \times W \times C}$，其中 $y_{i,j} \in \mathbb{R}^{C \times 1}$ 是位於空間位置 $(i, j)$ 處的特徵向量。規則卷積核的大小記為 $K \times K$。類似於公式 (1)，在單通道下，位於空間位置 $(i, j)$ 的網格單元上進行卷積操作的輸出值定義為：

$$
f_{\text{out}}(d_{i,j}) = \sum_{d_{m,n} \in B_D(d_{i,j})} w_k y_{m,n}, \tag{2}
$$

其中 $B_D(d_{i,j})$ 是網格單元 $d_{i,j}$ 的鄰居集合，這是一個以 $d_{i,j}$ 為中心的 $K \times K$ 子補丁，包含 $K^2$ 個網格單元；集合 $\{w_k \in \mathbb{R}^{1 \times C} | k = 1, ..., K^2\}$ 構成了一個正方形卷積核，用於與網格單元 $d_{i,j}$ 的鄰居集合中的特徵進行內積計算，如圖 1 所示。與圖卷積形成鮮明對比的是，我們 Ske2Grid 中的正方形卷積核在整個網格補丁中是共享的，這是建模規則鄰居集合中可學習網格單元集的關鍵。現在的問題是，如何學習網格補丁的合理佈局，從而使相鄰的網格單元在動作表示上具有表達能力。

![[PaperWithCode/16-Ske2Grid/Figure1.png]]
圖 1. GCN 和我們的 Ske2Grid 中卷積運算的比較。圖卷積（左上）通常使用特定內核將每個節點與其相鄰節點進行卷積。在 Ske2Grid 中，我們透過上取樣變換（UPT）和圖節點索引變換（GIT）建構了用於骨架表示的規則網格補丁。對此網格修補程式的捲積操作使用共用的常規核心對每個網格單元進行卷積。它在方形子補丁內的一組網格單元上運行，這些子補丁可以由圖形上遠端分佈的一組節點填充，從而在骨架上實現可學習的感受野以進行動作特徵建模（右上）。在圖中，為了更好地說明，假設原始圖節點的位置不變，上採樣的骨架圖被視覺化。

### **3.3. Graph-node Index Transform**

如上所述，網格補丁是通過將圖中的節點逐一分配到網格單元來構建的。問題在於如何為每個網格單元填充合適的圖節點，以改進特徵交互建模。我們提出學習一個從圖中節點索引到網格單元空間索引 $D_{H×W}$ 的映射，稱之為 **Graph-node Index Transform (GIT)**。

從 $N$ 個圖節點到網格補丁 $D_{H×W}$ 的 GIT 通過一個二進制矩陣 $\Phi \in \{0, 1\}^{HW × N}$ 定義，其中每一行$\phi_i \in \{0, 1\}^N$ 是一個 one-hot 向量，表示圖中選擇的節點的索引。也就是說，網格單元 $d_i$ 只有在 $\phi_{i,j} = 1$ 時才會被特定圖節點 $v_j$ 填充。根據這一定義，網格補丁 $D_{H×W}$ 的特徵可以通過以下公式獲得：

$$
Y = \text{reshape}(\Phi \cdot X), \tag{3}
$$

其中 “·” 表示按行與列相乘，乘積矩陣的每一行都是所選圖節點的特徵。`reshape(·)` 操作將$\Phi \cdot X$ 的輸出重新排列成 $H × W$ 的網格補丁表示。因此，網格補丁的佈局可以與 $\Phi$ 一起學習。

然而，直接學習二進制矩陣會切斷反向梯度流，這將使得訓練變得不可微分。為了解決這個問題，我們使用了 **直通估計器 (STE)** (Courbariaux et al., 2015) 來進行參數更新。具體來說，我們引入了一個實數矩陣 $\Psi \in \mathbb{R}^{HW × N}$ 來幫助學習 $\Phi$。在訓練過程中，我們根據以下公式逐行二值化 $\Psi$ 來獲得 $\Phi$：

$$
\phi_{i,j} = \begin{cases} 
1 & \text{if } \psi_{i,j} = \max(\psi_{i,·}), \\
0 & \text{otherwise}.
\end{cases} \tag{4}
$$

具體來說，對應於每行 $\Psi$ 中的最大值位置的元素被設置為 1，其他位置設置為 0。在反向傳播中，使用連續的梯度來更新實數矩陣 $\Psi$，而不是 $\Phi$。原則上，通過引入 $\Psi$ 作為 $\Phi$ 的連續近似值，它能夠幫助搜索出更好的網格補丁佈局，以提升動作表示的表達能力。

### **3.4. 上採樣轉換**

為了避免從骨架到網格表示的轉換過程中丟失信息，網格單元的數量應至少與骨架關節的數量相同，這樣所有的骨架關節都可以通過使 GIT 成為**滿射**（surjection）被分配到網格補丁中。然而，目標網格補丁中的網格單元數通常比圖節點數多，這意味著有一些額外的網格單元需要填充。如果這些網格單元是通過重複填充圖節點，這樣的優化問題並不簡單，可能會降低網格表示的表達能力。

為了進一步確保 GIT 是一個**雙射**（bijection），我們引入了一個**上採樣轉換**（UPT）來對骨架圖節點進行插值，從而完全填充網格補丁。上採樣後的圖的特徵圖可以通過以下公式獲得：

$$
X′ = Λ \cdot X, \tag{5}
$$

其中，$Λ \in \mathbb{R}^{HW×N}$ 表示上採樣矩陣，而 $X′ \in \mathbb{R}^{HW×C}$ 是上採樣後的特徵。考慮到骨架圖的原始拓撲結構反映了關節在執行動作時的協同運動，我們進一步提出將**鄰接矩陣**（adjacency matrix）引入公式 (5) 中，以規範上採樣過程：

$$
X′ = (Λ \cdot A) \cdot X, \tag{6}
$$

利用鄰接矩陣 $A$ 鼓勵 UPT 通過沿著現有邊的鄰近節點來進行節點插值，這樣可以在骨架到網格的表示過程中與拓撲先驗關聯，以改進動作表徵能力。

在經過 UPT 後，我們可以使用公式 (3) 來獲得上採樣後的特徵並進行一對一的索引映射，從而得到最終的網格表示。原則上，UPT 的主要思路是學習插值骨架圖節點，以提高表達能力，同時確保接下來構建網格補丁的 GIT 是雙射的。一般來說，可以通過多種方式使 GIT 成為雙射。在我們的情況下，我們通過簡單的**貪婪搜索**在公式 (4) 的二值化過程中對每行 $\Psi$ 進行二值化並添加不重複約束來實現。


### **3.5. 漸進學習策略**

通過 GIT 和 UPT，骨架輸入可以轉換為任意大小的網格補丁。在基於圖像的任務中，當輸入解析度增加時，CNN 模型通常會顯示出性能的提升。然而，在我們的方法中，當直接增加網格補丁的大小時，性能提升是有限的。我們推測，這是由於單步 UPT 和 GIT 的轉換對與直接學習策略之間存在不匹配，導致當單步 UPT 過於激進時，性能會略低於原始的骨架圖。

為了解決這一問題，我們提出了一種**漸進學習策略**（PLS），這是一種新穎的優化方案，它將激進的單步 UPT 分解為多步，並將其與多個 GIT 配對，通過一種緊湊的級聯設計進行漸進學習。這樣，網格表示可以通過逐步增加網格補丁的大小來逐步豐富其表達能力。

具體來說，我們首先學習將骨架圖轉換為一個基本網格補丁 $D^{H×W}$。然後，第一階段的 UPT 和 GIT 轉換對被重複使用，將骨架轉換為更大的網格補丁 $D^{H′×W′}$，其中 $H′ > H$ 且 $W′ > W$。這個過程可以形式化定義為：

$$
Y = reshape(Φ_2 · (Λ_2 · (Φ · ((Λ · A) · X)))), \tag{7}
$$

其中，$Φ · ((Λ · A) · X)$ 利用第一階段的 UPT 和 GIT 轉換對構建基本網格補丁 $D^{H×W}$，如公式 (6) 和公式 (3) 所定義；$Λ_2 ∈ R^{H′W′×HW}$ 是第二階段的 UPT，用於將網格補丁從基本大小 $H×W$ 上採樣到目標大小 $H′×W′$，而 $Φ_2 ∈ R^{H′W′×H′W′}$ 是第二階段的 GIT，用於將上採樣後的特徵分配到目標網格補丁。

第一階段學習的 UPT 和 GIT 轉換對在學習第二階段時保持不變。此外，Ske2Grid 卷積網絡在不同的訓練階段中保持相同的結構，因此在第二階段中，第一階段訓練的網絡可以作為預訓練模型來初始化網絡的訓練。這兩個方面構成了 PLS，該策略可以自然地以多個 UPT 和 GIT 配對的級聯方式使用，以提升 Ske2Grid 卷積網絡的性能。由於 UPT 和 GIT 的輕量化設計，它們在推理過程中對 Ske2Grid 卷積網絡引入的額外計算成本幾乎可以忽略不計。通過 PLS 促進的多個 UPT 和 GIT 配對的級聯結構，將從原始圖節點插值出的額外節點納入其中，並使得常規卷積可以捕獲各種有序的拓撲關係，從而增強我們網格補丁的表示學習能力。

### **3.6. 網絡構建**

基於上述網格表示學習的設計，Ske2Grid 中的卷積操作可以為動作表示建模學習一組豐富的網格單元。網格補丁被輸入到 Ske2Grid 卷積網絡中進行動作識別，如圖 2 所示。在 PLS 的輔助下，通過端到端聯合訓練 UPT、GIT 和 Ske2Grid 卷積網絡，可以在目標動作識別數據集的條件下自動學習骨架上的拓撲連接。為了使 Ske2Grid 適用於流行的 GCN 架構，而不修改它們的內建時間模塊，我們基於現有 GCN 架構構建 Ske2Grid 卷積網絡，僅將空間圖卷積替換為我們可學習的網格補丁上的卷積操作，而不改變骨幹網絡的結構和時間模塊。

![[PaperWithCode/16-Ske2Grid/Figure2.png]]
圖 2. (a) Ske2Grid 的整體架構：使用一對上取樣變換（UPT）和圖節點索引變換（GIT）將具有 N 個關節的輸入骨架圖轉換為大小為 H×W 的網格區塊，然後將其輸入Ske2Grid 卷積網路進行動作辨識。 (b) 採用漸進式學習策略 (PLS) 的 Ske2Grid：使用兩階段 UPT 加 GIT 對將輸入骨架轉換為更大的網格區塊 (H′ > H, W′ > W )。 (a) 中經過良好訓練的第一階段網格補丁的 Ske2Grid 卷積網絡被重新用於初始化第二階段網格補丁的網絡，如 (b) 中，第一階段 UPT 加 GIT 對是訓練期間固定。 PLS 以級聯方式使用，透過增加網格塊大小來提高 Ske2Grid 卷積網路的效能。

---

## **4. 實驗**

### **4.1. 數據集**

我們在實驗中考慮了六個主流數據集。

- **NTU-60** (Shahroudy et al., 2016) 是首個大規模多模態骨架動作識別數據集。它包含 56,880 個骨架動作序列，這些動作由 40 名志願者執行，分為 60 個類別。該數據集有兩個流行的驗證協議：跨主體 (XSub) 和跨視角 (XView)。
- **NTU-120** (Liu et al., 2019) 是 NTU-60 的擴展版本，包含來自 60 個額外動作類別的額外 57,367 個骨架序列。這個數據集的兩個流行驗證協議是：跨主體 (XSub) 和跨設置 (XSet)。
- **FineGym99** (Shao et al., 2020) 是一個新發布的精細動作識別數據集，包含 29,000 個體操動作類別的視頻，分為 99 個類別。
- **HMDB51** (Kuehne et al., 2011) 和 **UCF101** (Soomro et al., 2012) 是兩個早期流行的動作識別數據集，從網絡中收集。HMDB51 包含來自 51 個類別的 6,700 個視頻，而 UCF101 包含來自 101 個類別的 13,000 個視頻。
- **Diving48** (Li et al., 2018b) 包含超過 18,000 段競技跳水動作視頻，涵蓋了 48 個精細跳水類別。

**骨架數據集**：關於 2D 骨架估計實驗，我們使用 PYSKL (Duan et al., 2022b) 提供的這些數據集上的 2D 姿勢進行公平比較，這些姿勢是由 COCO (Lin et al., 2014) 預訓練的 HRNet (Sun et al., 2019) 檢測的。FineGym99 上有真實的 (GT) 人體邊界框，而其他數據集上的人體檢測器是基於 ResNet50 (He et al., 2016) 的 Faster-RCNN (Ren et al., 2015)。在 NTU-60 和 NTU-120 上使用 3D GT 骨架的實驗中，我們也使用 PYSKL 提供的這些數據集上的預處理 3D 姿勢進行公平比較。

---

### **4.2. 實現細節**

關於骨架輸入，我們對於 2D 骨架輸入使用 2D 關節坐標和估計分數作為關節特徵，對於 GT 3D 骨架輸入使用 3D 關節坐標，因此在這兩種情況下$C = 3$。對於骨架到網格表示變換的初始化，我們在 GIT 中對$\Psi$使用隨機初始化。為了更好地享受 UPT 中鄰接矩陣的調節，$\Lambda$初始化為一個$N \times N$的單位矩陣，並附加一個隨機矩陣。

關於網絡構建，我們選擇主流的 ST-GCN (Yan et al., 2018) 作為骨幹網絡，並通過將空間圖卷積替換為我們的網格補丁上的常規 2D 卷積來修改基本塊，如圖 3 所示。我們將此修改後的網絡稱為 ST-GCN⋆。除非另有說明，否則卷積核大小為 3×3。用於 $D^{H×W}$ 的 UPT 和 GIT 轉換對被添加到動作識別網絡之前，構建我們的基本 Ske2Grid $H×W$ 框架。

為了公平比較，我們使用流行的骨架動作識別綜合工具箱 PYSKL (Duan et al., 2022b) 來實現所有實驗。主要有兩種訓練設置。對於探索我們核心設計效果的實驗，我們使用與 ST-GCN (Yan et al., 2018) 中相同的 PYSKL 標準訓練策略，以進行公平和簡單的比較，每個模型訓練 80 個 epoch，並在第 10 和第 50 個 epoch 分別將學習率衰減 10 倍。對於表 2、表 3、表 8 和表 7 中顯示的主要實驗，我們使用 PYSKL 中的最新通用實驗設置，每個模型訓練 80 個 epoch，並使用余弦學習率調度。在這兩種設置中，初始學習率設置為 0.1，批量大小為 128，動量設置為 0.9，權重衰減設置為$5 \times 10^{-4}$，並在優化器中使用 Nesterov 動量。我們在所有實驗中報告驗證 top-1 準確率，除了表 7。當與最新方法比較時，我們還遵循 Duan et al. (2022c) 中的常見做法，報告測試 top-1 準確率，以進行公平比較，這略高於驗證性能，因為使用了數據增強技術。

![[PaperWithCode/16-Ske2Grid/Figure3.png]]
圖 3.ST-GCN 塊 (a) 和我們的 $ST-GCN^*$塊 (b) 之間的差異。

![[PaperWithCode/16-Ske2Grid/Table1.png]]
表 1. 使用 NTU-60 XSub 基準測試學習 Ske2Grid 中網格表示的三種關鍵設計的效果。

![[PaperWithCode/16-Ske2Grid/Table2.png]]
表 2. 我們的 Ske2Grid 使用 2D 估計骨架在六個資料集上的主要結果。我們報告了 $Ske2Grid_{8×8} $的性能。

![[PaperWithCode/16-Ske2Grid/Table3.png]]
表 3. 使用 3D GT 骨架輸入的 Ske2Grid 的效能比較。我們報告了 $Ske2Grid_{9×9}$ 的性能。

### **4.3. Ske2Grid 核心設計的效果**

我們首先進行實驗，分析我們學習網格表示的三個核心設計對 Ske2Grid 的影響，包括 UPT、GIT 和 PLS。我們比較了 ST-GCN⋆ 使用不同這三種設計組合學習網格補丁的性能，如表 1 所示。"PLS" 設置表示從 $Ske2Grid_{(H-1)×(W-1)}$ 逐步訓練 $Ske2Grid_{H×W}$。

僅使用 "GIT-only" 的 Ske2Grid 用所有不同的圖節點填充網格單元，並且剩餘的網格單元沒有重複約束。結果顯示，性能與網格補丁大小之間沒有明顯的關聯。結合 "PLS"，隨著網格補丁大小的增加，性能逐步提高，但性能增益並不顯著，這可能是由於多餘網格單元帶來的不確定性。

使用 "GIT & UPT" 設置時，Ske2Grid 的性能穩定超過基線。然而，當網格補丁增大到 D9×9 時，性能下降至基線以下。在這種情況下，網格單元的數量大約是骨架輸入關節數的五倍。僅使用一次 UPT 很難滿意地插值骨架圖，從而保證足夠的表現力。

結合這三種設計後，我們的 Ske2Grid 在性能上穩定超越基線，並且隨著網格補丁大小的增大，性能逐步提高，當使用 $D_{8×8}$ 時，實現了 3.3% 的 top-1 性能提升，充分展示了我們的 Ske2Grid 在動作識別中改進骨架特徵學習的有效性。在後續的主要實驗中，我們使用所有三種設計來訓練 Ske2Grid 模型。考慮到訓練負擔，我們最多將逐步學習策略級聯三次（即四個階段），例如，對 2D 估計骨架輸入，從 $D_{5×5}$ 開始，逐步以 1 為步長增加至 $D_{8×8}$。

---

### **4.4. 主要結果**

表 2 顯示了我們 Ske2Grid 在六個動作識別數據集上使用  $D_{8×8}$ 的主要結果。可以看到，我們的方法在所有數據集上穩定超過基線，顯示出其在改進骨架動作識別上的良好泛化能力。在這些數據集中，FineGym99 上的性能提升相對較小，這可能是因為該數據集上的 2D 估計骨架基於 GT（真實）人體邊界框，與其他數據集相比更加準確，因此我們的網格表示帶來的性能提升較小。這一推測在 Diving48 上得到了驗證，該數據集包含具有挑戰性的精細動作分類，且其相對不準確的 2D 骨架在識別精細動作時從我們的豐富網格表示中受益最多。

---

### **4.5. 消融實驗**

我們還提供了一些消融實驗，以深入分析我們的 Ske2Grid。

**使用 3D 骨架輸入的 Ske2Grid**：除了 2D 估計骨架輸入外，我們還使用由 25 個關鍵點組成的 NTU-60 和 NTU-120 的 3D 真實骨架進行實驗，如表 3 所示。我們的 Ske2Grid 從 $D_{6×6}$ 開始，逐步增大到 $D_{9×9}$。結果顯示，我們的方法在這兩個數據集的不同驗證協議下均超越基線，展示了我們 Ske2Grid 在改進基於運動捕捉的骨架動作識別中的強大泛化能力。

**卷積操作的影響**：為了分析卷積操作在我們 Ske2Grid 中的影響，我們使用圖卷積來直接建模網格表示，將網格補丁視為具有相鄰網格單元之間垂直和水平連接的常規圖，如表 4 所示。

![[PaperWithCode/16-Ske2Grid/Table4.png]]
表 4. 使用 NTU-60 XSub 基準測試的 Ske2Grid 中卷積運算的影響。我們使用 ST-GCN 直接對 UPT 和 GIT 獲得的網格補丁進行建模。 ST-GCN⋆使用我們的Ske2Grid中定義的捲積。 「◇」表示該變換是經過充分學習並在訓練期間固定的。

首先，ST-GCN 被用來建模帶有可學習的 UPT 和 GIT 的網格補丁。毫不意外地，性能顯著下降。正如前面所討論的，圖卷積使用其特定的內核將每個網格單元與其相鄰網格單元進行卷積。由於網格補丁的佈局是隨著網絡學習的，因此很難適應圖卷積來建模訓練期間網格單元之間不斷變化的拓撲關係。

其次，我們重新使用我們 Ske2Grid 已經學到的 UPT 和 GIT 來訓練 ST-GCN 以建模網格補丁。如結果所示，當固定 UPT 和 GIT 時，性能相對較好，說明圖卷積在建模固定圖時有一定的能力。然而，網格補丁的固定佈局仍然限制了骨架在動作表示中的表現力。ST-GCN⋆ 在可學習網格補丁下達到了最佳性能，展示了我們的卷積操作在學習動作識別中可學習網格單元之間的特徵交互的有效性。

**不同 PLS 設置的影響**：我們全面探索了網格補丁的起始大小和 PLS 中的漸進步驟，如表 5 所示。在所有不同設置下，性能都逐步提高。結果顯示，當從與骨架輸入關節數量接近的小網格補丁開始並以步長 1 逐步進行時，Ske2Grid 的性能更好。

![[PaperWithCode/16-Ske2Grid/Table5.png]]
表 5. 使用 NTU-60 XSub 基準測試的 Ske2Grid 中 PLS 設定的不同基礎網格修補程式和漸進步驟的效能 (%) 比較。 $D_K$ 是 $D_{K×K}$ 的縮寫。

**使用不同網格補丁大小的 Ske2Grid**：表 6 顯示了我們的 Ske2Grid 在不使用 PLS 設置時使用不同網格補丁大小的性能。我們可以看到，使用方形網格補丁的性能略好於使用矩形網格補丁。因此，我們在實驗中默認使用方形網格補丁。

![[PaperWithCode/16-Ske2Grid/Table6.png]]
表 6. 使用 NTU-60 XSub 基準測試在 Ske2Grid 中使用其他網格區塊大小時的效能比較。

**應用於其他 GCN 的 Ske2Grid**：我們基於 CTR-GCN (Chen et al., 2021) 構建網絡，通過將其空間建模中的圖卷積替換為我們的卷積操作，性能如表 8 所示。儘管 CTR-GCN 是一個最近的先進 GCN 解決方案，我們的 Ske2Grid 在相同的基準設置下仍然取得了可接受的性能增益。

**Ske2Grid 中學習佈局的可視化**：Ske2Grid 中的網格補丁由上採樣的圖節點填充，其佈局反映了骨架圖中關節的拓撲關係。我們在圖 4 中可視化了 $Ske2Grid_{8×8}$ 中逐步學習的網格補丁佈局中圖節點之間的連接，展示了我們的方法在建模可學習骨架特徵交互方面的能力。

**Ske2Grid 與最新方法的比較** 表 7 顯示了我們的 Ske2Grid 與多種最新技術方法在 NTU-60 和 NTU-120 數據集上的性能比較。我們收集了所有方法在原始論文中報告的最佳結果，這些方法都在 PoseConv3D (Yan et al., 2019) 之前提出。流行的基於 GCN 的方法（表中前 7 種解決方案）通過構建具有動態拓撲的骨架圖，並加入額外的上下文信息來擴大圖卷積的感受野，從而改進了 ST-GCN，這些技術細節我們在第 2 節討論過。最近提出的超圖和 Transformer 方法（表中間的 5 種解決方案）要麼引入局部和全局的超邊來編碼更高階的特徵依賴關係，要麼將人體的每個關節視為一個 token，然後使用空間和時間的自注意力操作來捕捉特徵依賴關係。正如結果所示，我們的 Ske2Grid 僅使用單一的“關節”模態就超越或達到了與這些現有解決方案相當的性能。PoseConv3D (Yan et al., 2019) 使用從 2D 姿態估計器獲取的骨架關節堆疊熱圖（空間大小為 56×56）作為輸入，並利用計算密集型的 3D CNN 來識別動作。相比之下，我們的 Ske2Grid 使用空間大小為 8×8 的更為緊湊的網格表示，以及輕量級的 2D 卷積網絡，實現了與 PoseConv3D 相當的性能，這是一個相當有希望的結果。利用 Ske2Grid 的逐步訓練優勢，我們將從 $D_{5×5}$ 到 $D_{8×8}$ 的四個模型進行集成，獲得了顯著的性能提升，展示了不同網格補丁大小之間的互補性。當進一步結合骨、關節運動和骨運動等其他方法常用的模態後，我們的 Ske2Grid 在四個基準測試中的三個中取得了最佳表現。


![[PaperWithCode/16-Ske2Grid/Figure4.png]]
圖 4. (a) D5×5 所反映的骨架圖上學習到的拓樸關係的可視化； (b)$D_{6×6}$； (c)$D_{7×7}$。


![[PaperWithCode/16-Ske2Grid/Table7.png]]
表 7. 使用估計的 2D 骨架，我們的 Ske2Grid 與 NTU-60 和 NTU-120 上最先進的方法的性能 (%) 比較。我們報告了 $Ske2Grid_{8×8}$ 的性能。 「J」、「B」、「JM」和「BM」分別表示關節、骨骼、關節運動和骨骼運動資料模態。 「◇」表示使用與Duan等人提供的相同的人體骨骼。 （2022b）。 「`*`」代表我們的Ske2Grid從 $D_{5×5}$ 到 $D_{8×8}$ 的平均模型融合。最佳結果以粗體顯示。

![[PaperWithCode/16-Ske2Grid/Table8.png]]
表 8. 我們的 Ske2Grid 使用 3D GT 骨架在 CTR-GCN（Chen 等人，2021）上建立網路時的效能 (%) 比較。我們報告了 $Ske2Grid_{9×9}$ 的性能。

---

## **5. 結論**

本文提出了 Ske2Grid，一個改進骨架動作識別的全新表示學習框架。在 Ske2Grid 中，我們基於 UPT、GIT 和 PLS 三個新設計構建和學習了緊湊的類圖像網格補丁，並在其上定義了常規卷積操作。網格表示的佈局由 Ske2Grid 卷積網絡學習，網格補丁上的卷積操作可以學習一組可學習的網格單元，從而改進了主動協調的人體關節之間的特徵交互建模，以進行有效的動作識別。我們在六個公共基準數據集上的實驗充分驗證了 Ske2Grid 的有效性。