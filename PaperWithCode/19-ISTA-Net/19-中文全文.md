#資料集/ntu120 #資料集/SBU #資料集/H2O #骨架偵測/tools/Kinectv2 #資料集/Assembly101  #骨架偵測/tools/MegaTrack #動作識別/演算法/Transformer #動作識別/演算法/CNN #運行框架/CTR-GCN 

摘要— 互動行為識別在人機交互和協作中扮演著重要角色。以往的方法通常使用後期融合（late fusion）和共同注意力機制（co-attention mechanism）來捕捉互動關係，但這些方法在學習能力上有限，或者在應對更多互動實體時效率不高。這些方法假設每個實體的先驗知識已知，因此缺乏針對多樣化主體情境的評估。為了解決這些問題，我們提出了一個交互時空令牌注意網絡（Interactive Spatiotemporal Token Attention Network，ISTANet），該網絡可以同時對空間、時間和互動關係進行建模。具體來說，我們的網絡包含一個令牌生成器，用來劃分交互時空令牌（Interactive Spatiotemporal Tokens, ISTs），這是一種統一表示多個多樣化實體動作的方式。透過擴展實體維度，ISTs 提供了更好的互動表徵。為了能夠在 ISTs 中聯合學習三個維度，我們設計了整合 3D 卷積的多頭自注意力模塊來捕捉令牌之間的相關性。在建模相關性時，實體的嚴格順序通常對於識別互動行為並不重要。為此，我們提出了實體重排（Entity Rearrangement）方法，旨在消除可互換實體之間的順序性。在四個數據集上的大量實驗驗證了 ISTA-Net 的有效性，其性能超越了現有的最新方法。我們的代碼已公開發布，網址為：https://github.com/Necolizer/ISTA-Net。

## I. 引言

互動行為識別是計算機視覺和物理人機交互中一項至關重要且具有挑戰性的任務 [1]–[4]，在許多應用場景中扮演著關鍵角色，例如輔助家務機器人 [5] 和互動機械臂 [6]。這些智能助手需要理解互動的運動模式以及動作背後的意圖，以確保人機協作的安全性和可靠性 [7], [8]。

互動行為是一種涉及多個實體相互依賴的物理動態的有目的行為。這種實體的相互依賴性使得互動行為有別於個體行為和群體活動。個體行為（圖1 (a)）專注於單個主體的動作。群體活動（圖1 (b)）是基於共同目標的動作所總結或抽象出的事件，其中包含了許多無關緊要且噪音較多的個體行為。相較之下，互動行為中的每個主體都是不可或缺的，缺少任何一方都無法完整地表達行為的語義。互動行為的類型包括人對人、手對手以及手對物體的互動。多樣化的互動實體具有不同的物理結構和互動模式，這使得在建模互動行為時變得更加複雜和多變。

近年來，有關互動行為建模的研究開始出現 [12]–[15]，但這些研究僅涉及圖1 (c) 中所描繪的一種特定類型的互動。他們還假設每個互動實體的物理連接已知且保持不變。因此，這些方法在解決涉及多樣化互動實體的常規場景時，缺乏評估。在本文中，我們專注於一項常規的互動行為識別任務，這是對以主體類型為基礎的任務進行的一般化，如圖1 (d) 所示。此外，先前的設計在捕捉互動關係方面存在局限性。後期融合（late fusion）提供了一種簡單的互動關係建模方法，但它在處理複雜互動時缺乏能力。另一方面，將共同注意力（co-attention）架構擴展以適應多於兩個的互動實體時，效率低下，因為隨著實體數量的增加，成對注意力分數的計算需求會急劇增加。因此，出現了一個重要的問題：如何聯合學習多樣化互動主體之間的空間、時間和互動關係？

為了回答這個問題，我們同時對互動主體之間的實體、時間和空間關係進行建模，並提出了一個交互時空令牌注意網絡（Interactive Spatiotemporal Token Attention Network，ISTA-Net）。其核心組件是交互時空令牌化（Interactive Spatiotemporal Tokenization）。通過這種令牌化，我們可以生成三維交互時空令牌（3D Interactive Spatiotemporal Tokens, ISTs），這是一種統一表示多個多樣化實體運動的方式。

為了學習令牌之間的相關性，我們將3D卷積與自注意力相結合，設計了令牌自注意力模塊（Token Self-Attention Blocks）。此外，對於建模實體之間的相關性，實體的順序並不必要。我們提出了實體重排（Entity Rearrangement）來解決這一問題，消除 ISTs 中可互換實體的順序性。

本文的主要貢獻如下：
- 我們提出了一個==交互時空令牌注意網絡（ISTA-Net），用於解決常規的互動行為識別任務，該方法不需要對主體的物理結構有先驗知識。==
- 我們提出了==交互時空令牌（Interactive Spatiotemporal Tokens），能夠融合三維交互時空特徵，有效表示多樣化實體的時空交互。==我們還設計了==令牌自注意力模塊（Token Self-Attention Blocks）來更好地捕捉不同交互特徵之間的相關性。==此外，==實體重排（Entity Rearrangement）確保了 ISTs 中無序實體的內在排列不變性。==
- 我們在 NTU RGB+D 120、SBU Kinect-Interaction、H2O 和 Assembly101 數據集上的大量實驗表明，我們的方法優於大多數互動行為識別方法。我們的代碼已公開。

![[PaperWithCode/19-ISTA-Net/Figure1.png]]
圖 1. 個人行動 (a) [9]、團體活動 (b) [10] 和互動行動 (c) [9]、[11]、[12] 的例子。 (a) 單一姿勢的序列可以完整地描繪跳躍動作。 (b) 團體活動 無論行人如何，等待都會被註解。 (c) 每個實體都是交互動作的一個組成部分。以前的方法側重於其中一種類型的相互作用。 (d) 在本文中，我們評估了一般的互動動作辨識任務，該任務解決了互動主體的多樣性。

## II. 相關工作

### A. 動作識別  
大多數基於骨架的動作識別方法專注於開發有效的架構來識別個體動作。早期的方法 [16]–[20] 採用了 RNN 或 LSTM 來建模骨架序列中的長期上下文。隨後，許多基於圖卷積網絡（GCN）的模型被提出 [21]–[29]。為了促進通道拓撲的建模，CTR-GCN [25] 為所有通道學習了一個共享的拓撲，並對每個通道進行了細化。InfoGCN [29] 採用了一個新穎的學習目標來學習緊湊的潛在表示。最近的研究探索了將自注意力機制引入骨架時空建模的潛力 [30], [31]。例如，STSA-Net [31] 採用了一種時空片段編碼策略來融合不同幀之間的關節關係。

### B. 互動行為識別  
最近提出的互動行為識別模型 [12]–[15] 基於根據主體先驗知識專門設計的模塊來捕捉互動。TA-GCN [12] 使用拓撲感知的圖卷積網絡來建模手對物體的關係，該網絡中手的先驗圖依賴性是預定義的。對於人與人之間的互動行為，LSTM-IRN [14] 採用了關係推理來處理互動過程中人體關節之間的不同關係。IGFormer [15] 是首個採用基於 Transformer 的架構，並利用人體結構的先驗知識來設計共同注意力機制進行互動的模型。與上述方法不同的是，我們的方法使用了交互時空令牌（Interactive Spatiotemporal Tokens）作為早期融合來建模交互時空特徵，這也使 ISTA-Net 能夠處理多種互動，如人對人、手對手以及手對物體的互動，而不需要基於特定主體類型的先驗知識手動預定義鄰接關係。

## III. ISTA-NET

本節介紹我們提出的交互時空令牌注意網絡 (ISTA-Net) 的架構，如圖 2 所示。輸入是一個交互動作，可以由不同類型的實體組成。首先，ISTA-Net 在訓練過程中進行實體重排，以保持無序主體的等效性。隨後，骨架張量通過 3D 滑動窗口進行分詞，然後交互式時空令牌 (IST) 被餵入多個 Token 自注意塊，以學習令牌級別的相互依賴性。最後，通過沿 IST 的全局平均池化 (GAP) 和全連接層 (FC) 進行預測。

![[PaperWithCode/19-ISTA-Net/Figure2.png]]
圖 2. 所提出的用於基於骨架的通用交互動作識別的 ISTA-Net 的總體架構。

### A. 交互骨架序列的交互時空令牌化

ISTA-Net 的一個重要方面是設計注意令牌，這些令牌代表交互骨架序列的交互時空局部特徵。我們提出了一種通用解決方案來表示多個骨架的運動，包括不同的主體，而無需假設每個交互實體的先驗知識已知。

假設有 $E$ 個交互實體在時間段 $T$ 內進行交互，每個實體包含 $J$ 個關節。根據是估計 2D 還是 3D 骨架，坐標維度 $C$ 可以是 2 或 3。因此，輸入骨架序列定義為 $X_{input} \in R^{C \times T \times J \times E}$。與個體動作相比，交互動作增加了表示交互實體部件或關節的維度 $E$，在對骨架數據進行分詞時必須考慮這一點。

我們的解決方案是使用不重疊的 3D 窗口來獲取交互時空令牌。此步驟稱為交互時空令牌化 (IST) 塊。給定大小為 $T_w \times J_w \times E_w$ 的窗口 $W$，它沿著時間、空間和交互維度滑動，以不重疊的方式劃分輸入數據。因此，大小為 $C \times T \times J \times E$ 的輸入被劃分為總共 $U = \lceil T / T_w \rceil \times \lceil J / J_w \rceil \times \lceil E / E_w \rceil$ 的補丁，大小為 $C \times T_w \times J_w \times E_w$，如下所示：
$$
X_w = IST(X_{input}, W), \tag{1}
$$
其中 $W \in \mathbb{R}^{T_w \times J_w \times E_w}$，$X_w \in \mathbb{R}^{C \times T_w \times (J_w \times E_w) \times U}$。

這些令牌 $X_w$ 可以被視為 $\mathbb{R}^{(C \times T_w \times J_w \times E_w) \times U}$ 的格式，更清楚地呈現為標準 Transformer 的輸入格式。然而，在這種情況下，我們保留了坐標維度 $C$ 和時間維度 $T_w$，以便在後續階段進行下採樣和時間聚合。

在某些情況下，如在 $T$ 通道中，輸入大小 $T$ 可能無法被窗口大小 $T_w$ 整除。在這種情況下，應沿著 $T$ 維度複製和填充原始張量的部分，創建時間通道中大小為 $T'$ 的新張量，其中 $T_w$ 是 $T'$ 的整除部分。

為了豐富坐標表示，使用 3D 的 1×1×1 卷積將坐標維度從 $C$ 擴展到 $C'$，其公式如下：
$$
X'_w = Conv3D(1 \times 1 \times 1)(X_w), \tag{2}
$$
其中 $X'_w \in \mathbb{R}^{C' \times T_w \times (J_w \times E_w) \times U}$。

卷積操作後接批量正規化和激活函數，作為交互時空令牌的嵌入層。最後，這些令牌 $X_{ist}$ 被餵入多個多頭自注意塊，以學習跨幀、關節和主體的高層次表示。

![[PaperWithCode/19-ISTA-Net/Algorithm1.png]]
演算法 1 具有實體重排的互動式時空標記化

### B. 實體重排

在分割 IST 和編碼位置信息時，嚴格的實體排序會妨礙學習的泛化能力。具體來說，對於參與相互動作的交互實體，有些是語義有序且不可互換的（例如左手、右手和物體），而其他的是無序且可互換的（例如人）。相互主體的語義等價意味著無序實體是置換不變的。它們可以按任何順序排列，仍然代表相同的交互動作。

這一觀察啟發了我們一種簡單而有效的方法來消除可互換實體的順序性。給定大小為 $C \times T \times J \times E$ 的輸入骨架序列，我們首先沿交互維度將其分為 $E$ 個部分，顯然每個部分代表一個主體的關節運動：
$$
[X_1, X_2, \dots, X_i, \dots, X_E] = Split(X_{input}), \tag{3}
$$
其中 [1, 2, · · ·, i, · · ·, E] 是沿交互維度的位置順序索引。

我們可以將原始 $X_{input}$ 重新排列如下：
$$
\tilde{X}_{input} = Concat([X_{v_1}, X_{v_2}, \dots, X_{v_i}, \dots, X_{v_E}]), \tag{4}
$$
其中 [v_1, v_2, · · ·, v_i, · · ·, v_E] 是索引 [1, 2, · · ·, i, · · ·, E] 的任意排列。

### C. 令牌自注意塊

為了同時建模空間、時間和交互關係，我們的架構採用了多頭自注意機制，而不是基於圖卷積的設計。不同於許多需要手動定義基於關節物理連接的鄰接列表的 GCN，我們提出的架構不需要這樣繁瑣的步驟，可以統一處理不同主體的交互行為識別。

我們的 ISTA-Net 由 L 個令牌自注意塊組成。類似於標準的多頭自注意，輸入 $X_{L_{i-1}}$ 轉換為多組查詢 $Q$、鍵 $K$ 和值 $V$，公式如下：
$$
Q = Conv3D(1 \times 1 \times 1)(X_{L_{i-1}} + P E(X_{L_{i-1}})), \tag{5}
$$
$$
K = Conv3D(1 \times 1 \times 1)(X_{L_{i-1}} + P E(X_{L_{i-1}})), \tag{6}
$$
$$
V = X_{L_{i-1}}, \tag{7}
$$
其中使用循環函數實現的位置編碼，表示為 $P E(\cdot)$。集合的數量，也就是所謂的注意頭數，記為 $H$。  
第 h 個頭的自注意力分數 $X_{Li}^h$ 可根據以下公式計算：  
$$
X^{Li}_h = (\alpha \cdot \tanh \left(\frac{Q K^T}{\sqrt{C_\beta}}\right) + M) V, \tag{8}
$$
其中 $Q K^T$ 被除以特徵長度的平方根 $C_\beta = T_w \times J_w \times E_w \times C_{Li-qkv}$。一個可訓練的正則化矩陣 $M \in R^{U \times U}$ 被添加到歸一化的注意力圖上，並引入了一個可訓練的平衡因子 $\alpha$，這對相關學習有幫助 [30]  [31] 。H 個頭的所有分數 $X^h_{Li}$ 被串聯起來得到 $X^H_{Li}$。

在一些 TSA 塊中，$C_{Li-1}$ 維度會加倍來對特徵進行下採樣（$C_{Li} = 2 \times C_{Li-1}$），而在其他 TSA 塊中，維度保持不變（$C_{Li} = C_{Li-1}$）：  
$$
\hat{X}_{Li} = \text{Conv3D}_{(1\times1\times k_u)}(X^H_{Li}), \tag{9}
$$
$$
\acute{X}_{Li} = \text{Conv3D}_{(1 \times 1 \times 1)}(\hat{X}_{Li} + X^{\text{Res}}_{Li}) + X^{\text{Res}}_{Li}, \tag{10}
$$
其中 3D 的 1 × 1 × 1 卷積與殘差連接實現了前饋網絡（FFN）。
最後一個組件是時間聚合（TA）層。先前的研究 [27]  [28] 表明，沿時間通道的特徵聚合對於動作建模是有效的。與這些方法不同，所提出的 ISTA-Net 使用時間維度上大於 1 的 3D 卷積核（$k_t > 1$）來聚合序列特徵：
$$
X_{Li} = \text{Conv3D}_{(k_t \times 1 \times 1)}(\acute{X}_{Li}) + \acute{X}^{\text{Res}}_{Li}, \tag{11}
$$
隨後是殘差連接 $\acute{X}^{\text{Res}}_{Li}$。

## IV. 實驗  

### A. 數據集  
**NTU RGB+D 120** [9] 是 NTU RGB+D [34] 的擴展版本，是一個廣泛使用的動作識別數據集，提供了 114,480 個樣本，涵蓋 120 種人類動作。在我們的實驗中，我們專注於 NTU RGB+D 120 數據集的一個子集，它包括 26 種互動行為（簡稱 NTU Mutual）。  
**SBU-Kinect-Interaction** [32] 是一個描繪人與人之間交互的人類活動數據集，包含八種交互行為，並提供了 RGB+D 視頻和提取的骨架數據。  
**H2O** [12] 是首個為自我中心的 3D 交互識別構建的數據集。該數據集提供了雙手的 3D 姿態和操控物體的姿態，便於理解手與手、手與物體之間的交互。  
**Assembly101** [33] 是一個大型的程序活動數據集，提供了 3D 手勢，以推動來自自我中心視角的 3D 交互識別。由於該數據集的複雜性，它的任務難度較高，包括超過 1,300 個細粒度的手與物體交互類別。每個類別由一個動詞和一個被操控的物體組成。此外，由於缺少物體姿態，使得判斷交互動作變得更加困難。  
這些數據集的統計數據和難點總結在表 I 和圖 3 中。對於 NTU Mutual 的評估，我們採用了 Cross-subject (X-Sub) 和 Cross-set (X-Set) 標準 [9]，僅使用關節模態以確保在無融合條件下進行公平比較。對於 SBU，我們採用了建議的五折交叉驗證方法 [32]。對於 H2O 和 Assembly101，我們遵循 [12] 和 [33] 中描述的訓練、驗證和測試劃分。

![[PaperWithCode/19-ISTA-Net/Table1.png]]
表 I 交互動作辨識資料集統計

![[PaperWithCode/19-ISTA-Net/Figure3.png]]
圖 3. 四個資料集中不同實體的交互動作辨識的困難。

### B. 實施細節  
我們的所有實驗都是在配備四張 GeForce RTX 3070 GPU 和 CUDA 版本 11.4 的機器上進行的。對於 NTU Mutual 數據集的訓練，我們使用了帶有 Nesterov 動量的 SGD 優化器，動量設置為 0.9，初始學習率為 0.1，衰減率為 0.1。窗口大小設置為 [20, 1, 2]。交叉熵用作損失函數，標籤平滑因子為 0.1，溫度因子為 1.0。批次大小為 32。每次訓練過程在 110 個 epoch 後終止。其他數據集的參數可能有所不同，請參閱我們 Github 存儲庫中的配置。

### C. 與相關方法的比較  
表 II 報告了 NTU Mutual、SBU、H2O 和 Assembly101 數據集上的實驗結果。與其他傳統動作識別和交互動作識別方法相比，所提出的 ISTA-Net 獲得了最先進的性能。得益於我們提出的 ISTs、TSA Blocks 和 ER，ISTA-Net 在許多基於 LSTM、GCN 和 Transformer 的動作識別方法上實現了超越。ISTA-Net 在 NTU Mutual X-Sub 和 X-Set、SBU 和 Assembly101 上分別比最相關的交互動作識別方法 IGFormer [15] 提高了 5.16%、5.22%、0.11% 和 5.68%。ISTA-Net 也分別在 NTU Mutual 上超越了 InfoGCN [29] 0.34% 和 0.59%，在 H2O 上比 TA-GCN [12] 提高了 9.84%，並且在 Assembly101 上比 MS-G3D [24] 提高了 1.15%。從結果可以看出，我們的 ISTA-Net 也展示了其對各種交互實體的優越性和適應性。圖 4 可視化了最後一個 TSA Block 中學到的注意力，驗證了 ISTA-Net 在建模交互動作時的有效性。

![[PaperWithCode/19-ISTA-Net/Table2.png]]
表 II 四種不同交互動作資料集上動作辨識方法的比較
$^1$ 表格報告了幾次種子初始化中的平均 top-1 準確度，以及括號中的標準差。不帶括號的統計數據引用自[12]、[15]、[33]。

![[PaperWithCode/19-ISTA-Net/Figure4.png]]
圖 4.從最後一個 TSA 區塊恢復的學習互動關係的視覺化。注意力權重被視覺化，以說明辨識不同互動動作所涉及的重要身體部位。具體來說，ISTA-Net 透過關注攻擊者的手和受害者的四肢來識別拳擊動作。擁抱動作是透過注意接近和接觸的身體部位來辨識的。給予對象的動作是透過對手的注意力來辨識的。

### D. 消融研究  
**交互關係融合方式的比較**：我們比較了四種方式來建模時空特徵的交互關係。第一種方法稱為後融合 (Late Fusion)，這是在適應交互骨架時傳統動作識別方法中常用的方式。後融合僅在分類頭中建模交互關係。第二種方法是共同注意 (Co-attention)，使用權重共享的雙分支自注意塊。在每個塊中，$K$ 和 $V$ 從此分支中的上一個塊獲得，而 $Q$ 從另一個分支獲得。第三種方法是座標拼接 (Coordinate Concat)，將實體特徵直接拼接到座標維度。最後一種是我們提出的 IST，它在早期分詞階段融合交互特徵，與其他方法相比，在這種方法中擴展了額外的維度 $E$。表 III 顯示，IST 分別比其他方法提高了 1.77%、0.78% 和 2.42%。

![[PaperWithCode/19-ISTA-Net/Table3.png]]
表 III  融合互動關係的方法比較


**實體重排的有效性**：我們通過刪除此步驟來探索實體重排的有效性。如表 IV 所報告，性能在相對較大的 NTU Mutual 數據集上有所下降，並且在相對較小的 SBU 數據集上下降更為明顯。這表明 ER 有助於提高模型的泛化性，特別是在使用小規模數據進行訓練時。

![[PaperWithCode/19-ISTA-Net/Table4.png]]
表 IV 實體重組的有效性

**時間聚合的有效性**：為了確認時間聚合所做的貢獻，我們刪除此步驟進行比較。表 V 中的結果表明，TA 可以有效地在 IST 中聚合局部時間運動特徵，並提高識別性能。

![[PaperWithCode/19-ISTA-Net/Table5.png]]
表 V 時間聚合的有效性

**不同輸入幀長和窗口大小的比較**：我們評估了不同的輸入幀長和窗口大小對 ISTA-Net 性能的影響。在 NTU 數據集中，60 和 120 是最廣泛採用的輸入幀長。為了確保公平比較，當使用不同的幀數時，窗口大小會在時間維度上進行相應的縮放，從而保持 IST 數量不變。表 VI 顯示，使用 120 幀作為輸入可獲得最佳性能，增加更多幀會引入額外的噪聲。表 VII 顯示，給定固定的幀數，窗口大小為 [20, 1, 2] 可帶來最佳結果，表明關節可以在更細粒度的水平上進行建模。

![[PaperWithCode/19-ISTA-Net/Table6.png]]
表 VI  使用不同輸入幀長度的性能

![[PaperWithCode/19-ISTA-Net/Table7.png]]
表 VII 使用不同視窗尺寸的效能

## V. 結論  
本文提出了交互時空令牌注意網絡 (ISTA-Net) 用於通用交互動作識別，不需要基於主體類型的圖先驗知識來建模多樣化的交互實體。我們的 ISTA-Net 由交互時空令牌化塊和令牌自注意塊組成。通過在注意令牌中擴展額外的實體維度，我們的設計可以同時有效地捕捉交互動作的交互和時空相關性。此外，我們引入了實體重排，以保持交互時空令牌中無序主體的無序性。我們的方法在四個交互動作識別基準數據集上展示了優越的性能和適應性。