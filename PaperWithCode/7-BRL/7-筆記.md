
長尾數據是指數據集中大多數樣本屬於少數幾個高頻類別，而其餘的類別只有少量樣本的情況。這種分佈特徵類似於長尾分佈（long-tailed distribution），即一小部分類別（頭部類別）包含大量的樣本，而大部分類別（尾部類別）只包含少量樣本。

在這樣的情況下，標準的機器學習模型往往更容易學習頭部類別的特徵，而忽略了尾部類別，這導致尾部類別的識別性能較差。


-----


==長尾數據導致樣本空間偏斜，從而引發表徵偏差，這是動作識別算法性能下降的主要原因之一。==


---

兩大核心組件：**時空動作探索策略（Spatial-Temporal Action Exploration, STAE）** 和 **獨立動作感知學習計劃（Detached Action-Aware Learning Schedule, DAA）**


### **時空動作探索策略（STAE）**

這個策略是為了生成更多有價值的樣本，通過空間和時間的結構信息來平衡數據分佈。STAE 策略包含兩個主要部分：

#### **重新平衡的部分混合（Rebalanced Partial Mixup, RPM）**

- **目的**：處理長尾數據中的樣本空間偏斜問題，特別是尾部類別數據稀少的情況。
- **原理**：在常規的 Mixup 方法基礎上，提出了部分混合策略，用於生成新的骨架樣本。不同於標準的 Mixup，RPM 只對部分骨架結構進行混合，並在樣本空間和標籤空間使用不同的混合係數來強化樣本生成過程中的重平衡。這樣的做法不僅擴展了樣本空間，還專注於生成有助於少數類別學習的數據。
- **具體實施**：該方法在樣本空間對骨架的不同關節進行選擇性混合，並根據樣本類別的不平衡度調整標籤混合的權重，使得少數類別在混合過程中佔據更高的權重，從而緩解不平衡數據帶來的偏差。

####  **時間逆向感知（Temporal Reverse Perception, TRP）**

- **目的**：針對長尾數據中的時間信息增強問題，特別是如何在尾部類別數據較少的情況下，有效利用骨架序列中的時間信息。
- **原理**：將原始骨架序列均勻地分割成等長片段，並從每個片段中隨機選擇一幀。這樣的策略使得生成的骨架序列具有相似的時間屬性，從而在保持時間完整性的同時增強數據的多樣性。這一策略特別有助於提升尾部類別的數據質量。
- **具體實施**：對尾部類別進行更多的抽樣，以生成更多具有時間區別的骨架樣本，進一步避免信息冗餘，並增強尾部類別的學習效果。

### **獨立動作感知學習計劃（DAA）**

DAA 是針對表徵偏差問題提出的學習計劃，它包含兩個核心部分：

#### **獨立的訓練策略（Detached Training Strategy）**

- **目的**：解決在整個訓練過程中對頭部類別過度依賴，從而影響尾部類別學習的問題。
- **原理**：將頭部類別與尾部類別的學習過程分離，讓模型首先從頭部類別中學習一般性的動作表徵，之後再專門學習尾部類別的特定模式。
- **具體實施**：模型在訓練初期使用標準的交叉熵損失函數（CE Loss）來學習動作的通用知識，經過幾個 epoch 後，過渡到引入動作感知損失函數，從而引導模型專注於尾部類別的學習，進而避免在訓練初期忽視尾部類別。

#### **動作感知損失（Action-Aware Loss）**

- **目的**：針對尾部類別數據稀少的情況，對尾部類別施加更多的學習權重，從而減輕表徵偏差。
- **原理**：引入一個動作感知項 β ，根據樣本數量和類別分佈來動態調整樣本的權重，從而對尾部類別施加更多的學習約束。
- **具體實施**：該損失函數會根據不同類別的樣本數，給尾部類別分配更高的權重，從而確保模型能夠學習尾部類別的特定特徵，並避免過度訓練頭部類別。

### 空間-時間動作探索策略（Spatial-Temporal Action Exploration, STAE）：
- 重新平衡的部分混合（Rebalanced Partial Mixup, RPM）：這是一種資料增強技術，透過對不同身體部位的骨架資料進行重新平衡的混合來產生新的樣本。它在樣本空間和標籤空間中使用不同的混合因子，以增強空間結構資訊。
- 時間反向感知（Temporal Reverse Perception, TRP）：這是一種時間資料增強技術，透過對原始序列進行均勻分割並隨機選擇幀來增強時間資訊。
### 分離的動作感知學習計劃（Detached Action-Aware Learning Schedule）：
這種學習計劃包括一個分離的訓練策略和一個動作感知損失（Action-Aware Loss）。它使得模型首先透過常規交叉熵損失學習到大多數類別的一般知識，然後透過動作感知損失關注尾部類別的特定模式。
### 多模態表示融合：
論文還提出了一種新的模態表示方法，稱為跳躍模態表示（Skip-Modal Representation），它通過跳過某些關節點來獲取更緊湊的空間關係信息，同時保持方向信息。
### ST-GCN++作為骨幹網路：
儘管論文提出的方法可以與任何動作識別骨幹網路結合使用，但實驗中選擇的骨幹網路是ST-GCN++，這是一個基於圖卷積網路（GCN）技術的最新代表性方法。